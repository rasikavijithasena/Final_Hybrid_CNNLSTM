{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('gm_merge.csv')\n",
    "# Inspect the data\n",
    "\n",
    "df['Date'] = df['Datetime'].str[:-6]\n",
    "df['Date']=pd.to_datetime(df[\"Date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_date = df.filter(['Date'])\n",
    "\n",
    "data_date = data_date.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_date = int(np.ceil( len(data_date) * .95 ))\n",
    "train_data_date = data_date[0:int(training_data_date), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Dropout, Activation, Conv1D\n",
    "from tensorflow.keras.layers import Dense, Input, RNN\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime     0\n",
      "Open         0\n",
      "High         0\n",
      "Low          0\n",
      "Close        0\n",
      "Adj Close    0\n",
      "Volume       0\n",
      "Date         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['Close']=df['Close']\n",
    "count_nan = len(df) - df.count()\n",
    "print(count_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "#Get /Compute the number of rows to train the model on\n",
    "# training_data_len = math.ceil( len(dataset) *.6)\n",
    "training_data_len = math.ceil( len(dataset)*.95) \n",
    "\n",
    "\n",
    "\n",
    "#Scale the all of the data to be values between 0 and 1 \n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "#Create the scaled training data set \n",
    "train_data = scaled_data[0:training_data_len  , : ]\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train=[]\n",
    "y_train = []\n",
    "for i in range(60,len(train_data)):\n",
    "    x_train.append(train_data[i-60:i,0])\n",
    "    y_train.append(train_data[i,0])\n",
    "\n",
    "\n",
    "#Convert x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)    \n",
    "\n",
    "\n",
    "#Reshape the data into the shape accepted by the LSTM\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data set\n",
    "test_data = scaled_data[training_data_len - 60: , : ]\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test =  dataset[training_data_len : , : ] \n",
    "for i in range(60,len(test_data)):\n",
    "    x_test.append(test_data[i-60:i,0])\n",
    "\n",
    "\n",
    "\n",
    "#Convert x_test to a numpy array \n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#Reshape the data into the shape accepted by the LSTM\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDimension = int(x_train.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = \"FastRNN\" \n",
    " \n",
    "inputDims = 1 #features taken in by RNN in one timestep\n",
    "hiddenDims = 50 #hidden state of RNN\n",
    " \n",
    "totalEpochs = 8\n",
    "batchSize = 64\n",
    " \n",
    "learningRate = 0.001 \n",
    "decayStep = 50\n",
    "decayRate = 0.1\n",
    " \n",
    "outFile = None\n",
    " \n",
    "\n",
    "wRank = None \n",
    "uRank = None \n",
    " \n",
    "\n",
    "sW = 1.0 \n",
    "sU = 1.0\n",
    " \n",
    "#Non-linearities for the RNN architecture. Can choose from \"tanh, sigmoid, relu, quantTanh, quantSigm\"\n",
    "update_non_linearity = \"relu\"\n",
    "gate_non_linearity = \"relu\"\n",
    "\n",
    "\n",
    "cell == \"FastRNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6604, 60, 1)\n",
      "(350, 60, 1)\n",
      "(6604, 60, 1)\n",
      "(350, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train = np.reshape(x_train,[x_train.shape[0],x_train.shape[1],1])\n",
    "print(x_test.shape)\n",
    "x_test = np.reshape(x_test,[x_test.shape[0],x_test.shape[1],1])\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "104/104 [==============================] - 14s 116ms/step - loss: 0.0108\n",
      "Epoch 2/100\n",
      "104/104 [==============================] - 9s 89ms/step - loss: 2.7787e-04\n",
      "Epoch 3/100\n",
      "104/104 [==============================] - 14s 137ms/step - loss: 2.1734e-04\n",
      "Epoch 4/100\n",
      "104/104 [==============================] - 20s 188ms/step - loss: 1.5491e-04\n",
      "Epoch 5/100\n",
      "104/104 [==============================] - 24s 234ms/step - loss: 1.2038e-04\n",
      "Epoch 6/100\n",
      "104/104 [==============================] - 25s 246ms/step - loss: 1.2036e-04\n",
      "Epoch 7/100\n",
      "104/104 [==============================] - 36s 348ms/step - loss: 1.2203e-04\n",
      "Epoch 8/100\n",
      "104/104 [==============================] - 43s 412ms/step - loss: 9.6805e-05\n",
      "Epoch 9/100\n",
      "104/104 [==============================] - 38s 365ms/step - loss: 8.2156e-05\n",
      "Epoch 10/100\n",
      "104/104 [==============================] - 44s 429ms/step - loss: 9.4475e-05\n",
      "Epoch 11/100\n",
      "104/104 [==============================] - 44s 423ms/step - loss: 9.4052e-05\n",
      "Epoch 12/100\n",
      "104/104 [==============================] - 42s 406ms/step - loss: 7.7989e-05\n",
      "Epoch 13/100\n",
      "104/104 [==============================] - 46s 442ms/step - loss: 7.7339e-05\n",
      "Epoch 14/100\n",
      "104/104 [==============================] - 50s 482ms/step - loss: 8.6390e-05\n",
      "Epoch 15/100\n",
      "104/104 [==============================] - 56s 543ms/step - loss: 7.6920e-05\n",
      "Epoch 16/100\n",
      "104/104 [==============================] - 57s 541ms/step - loss: 7.2599e-05\n",
      "Epoch 17/100\n",
      "104/104 [==============================] - 45s 433ms/step - loss: 6.7168e-05\n",
      "Epoch 18/100\n",
      "104/104 [==============================] - 50s 487ms/step - loss: 7.4961e-05\n",
      "Epoch 19/100\n",
      "104/104 [==============================] - 49s 478ms/step - loss: 7.6607e-05\n",
      "Epoch 20/100\n",
      "104/104 [==============================] - 55s 535ms/step - loss: 6.1821e-05\n",
      "Epoch 21/100\n",
      "104/104 [==============================] - 52s 495ms/step - loss: 6.8438e-05\n",
      "Epoch 22/100\n",
      "104/104 [==============================] - 51s 494ms/step - loss: 7.6023e-05\n",
      "Epoch 23/100\n",
      "104/104 [==============================] - 54s 522ms/step - loss: 1.0415e-04\n",
      "Epoch 24/100\n",
      "104/104 [==============================] - 52s 499ms/step - loss: 5.6771e-05\n",
      "Epoch 25/100\n",
      "104/104 [==============================] - 51s 491ms/step - loss: 6.4424e-05\n",
      "Epoch 26/100\n",
      "104/104 [==============================] - 45s 439ms/step - loss: 8.7531e-05\n",
      "Epoch 27/100\n",
      "104/104 [==============================] - 52s 500ms/step - loss: 5.5106e-05\n",
      "Epoch 28/100\n",
      "104/104 [==============================] - 51s 494ms/step - loss: 7.6711e-05\n",
      "Epoch 29/100\n",
      "104/104 [==============================] - 54s 518ms/step - loss: 6.5473e-05\n",
      "Epoch 30/100\n",
      "104/104 [==============================] - 54s 514ms/step - loss: 6.1393e-05\n",
      "Epoch 31/100\n",
      "104/104 [==============================] - 45s 430ms/step - loss: 6.5974e-05\n",
      "Epoch 32/100\n",
      "104/104 [==============================] - 41s 398ms/step - loss: 5.3277e-05\n",
      "Epoch 33/100\n",
      "104/104 [==============================] - 36s 351ms/step - loss: 1.2193e-04\n",
      "Epoch 34/100\n",
      "104/104 [==============================] - 46s 444ms/step - loss: 6.7770e-05\n",
      "Epoch 35/100\n",
      "104/104 [==============================] - 38s 369ms/step - loss: 5.7935e-05\n",
      "Epoch 36/100\n",
      "104/104 [==============================] - 50s 486ms/step - loss: 7.7257e-05\n",
      "Epoch 37/100\n",
      "104/104 [==============================] - 49s 478ms/step - loss: 6.4054e-05\n",
      "Epoch 38/100\n",
      "104/104 [==============================] - 41s 398ms/step - loss: 6.6555e-05\n",
      "Epoch 39/100\n",
      "104/104 [==============================] - 40s 382ms/step - loss: 6.2929e-05\n",
      "Epoch 40/100\n",
      "104/104 [==============================] - 36s 339ms/step - loss: 8.7619e-05\n",
      "Epoch 41/100\n",
      "104/104 [==============================] - 35s 334ms/step - loss: 6.8359e-05\n",
      "Epoch 42/100\n",
      "104/104 [==============================] - 35s 336ms/step - loss: 5.8375e-05\n",
      "Epoch 43/100\n",
      "104/104 [==============================] - 39s 379ms/step - loss: 5.8344e-05\n",
      "Epoch 44/100\n",
      "104/104 [==============================] - 36s 339ms/step - loss: 5.9304e-05\n",
      "Epoch 45/100\n",
      "104/104 [==============================] - 44s 429ms/step - loss: 7.2900e-05\n",
      "Epoch 46/100\n",
      "104/104 [==============================] - 37s 354ms/step - loss: 5.2284e-05\n",
      "Epoch 47/100\n",
      "104/104 [==============================] - 43s 412ms/step - loss: 5.6795e-05\n",
      "Epoch 48/100\n",
      "104/104 [==============================] - 45s 430ms/step - loss: 6.8490e-05\n",
      "Epoch 49/100\n",
      "104/104 [==============================] - 47s 454ms/step - loss: 5.7000e-05\n",
      "Epoch 50/100\n",
      "104/104 [==============================] - 49s 473ms/step - loss: 1.0389e-04\n",
      "Epoch 51/100\n",
      "104/104 [==============================] - 47s 453ms/step - loss: 7.0662e-05\n",
      "Epoch 52/100\n",
      "104/104 [==============================] - 52s 496ms/step - loss: 7.3855e-05\n",
      "Epoch 53/100\n",
      "104/104 [==============================] - 53s 513ms/step - loss: 4.7313e-05\n",
      "Epoch 54/100\n",
      "104/104 [==============================] - 42s 405ms/step - loss: 5.7930e-05\n",
      "Epoch 55/100\n",
      "104/104 [==============================] - 50s 480ms/step - loss: 5.6643e-05\n",
      "Epoch 56/100\n",
      "104/104 [==============================] - 49s 471ms/step - loss: 8.3679e-05\n",
      "Epoch 57/100\n",
      "104/104 [==============================] - 52s 501ms/step - loss: 9.9643e-05\n",
      "Epoch 58/100\n",
      "104/104 [==============================] - 39s 370ms/step - loss: 6.9025e-05\n",
      "Epoch 59/100\n",
      "104/104 [==============================] - 52s 499ms/step - loss: 4.4027e-05\n",
      "Epoch 60/100\n",
      "104/104 [==============================] - 46s 436ms/step - loss: 5.9639e-05\n",
      "Epoch 61/100\n",
      "104/104 [==============================] - 51s 496ms/step - loss: 5.5379e-05\n",
      "Epoch 62/100\n",
      "104/104 [==============================] - 48s 457ms/step - loss: 5.9906e-05\n",
      "Epoch 63/100\n",
      "104/104 [==============================] - 52s 493ms/step - loss: 5.9260e-05\n",
      "Epoch 64/100\n",
      "104/104 [==============================] - 50s 477ms/step - loss: 5.0871e-05\n",
      "Epoch 65/100\n",
      "104/104 [==============================] - 48s 462ms/step - loss: 4.6659e-05\n",
      "Epoch 66/100\n",
      "104/104 [==============================] - 51s 488ms/step - loss: 4.7977e-05\n",
      "Epoch 67/100\n",
      "104/104 [==============================] - 43s 420ms/step - loss: 5.4433e-05\n",
      "Epoch 68/100\n",
      "104/104 [==============================] - 46s 441ms/step - loss: 7.1839e-05\n",
      "Epoch 69/100\n",
      "104/104 [==============================] - 45s 431ms/step - loss: 8.4074e-05\n",
      "Epoch 70/100\n",
      "104/104 [==============================] - 39s 373ms/step - loss: 6.4424e-05\n",
      "Epoch 71/100\n",
      "104/104 [==============================] - 43s 418ms/step - loss: 5.9121e-05\n",
      "Epoch 72/100\n",
      "104/104 [==============================] - 35s 342ms/step - loss: 6.5811e-05\n",
      "Epoch 73/100\n",
      "104/104 [==============================] - 52s 503ms/step - loss: 5.9200e-05\n",
      "Epoch 74/100\n",
      "104/104 [==============================] - 47s 450ms/step - loss: 5.1372e-05\n",
      "Epoch 75/100\n",
      "104/104 [==============================] - 44s 422ms/step - loss: 5.5626e-05\n",
      "Epoch 76/100\n",
      "104/104 [==============================] - 37s 361ms/step - loss: 5.9255e-05\n",
      "Epoch 77/100\n",
      "104/104 [==============================] - 46s 436ms/step - loss: 7.4792e-05\n",
      "Epoch 78/100\n",
      "104/104 [==============================] - 43s 407ms/step - loss: 9.8029e-05\n",
      "Epoch 79/100\n",
      "104/104 [==============================] - 38s 370ms/step - loss: 4.8908e-05\n",
      "Epoch 80/100\n",
      "104/104 [==============================] - 46s 435ms/step - loss: 5.0822e-05\n",
      "Epoch 81/100\n",
      "104/104 [==============================] - 43s 412ms/step - loss: 4.7336e-05\n",
      "Epoch 82/100\n",
      "104/104 [==============================] - 43s 412ms/step - loss: 4.9772e-05\n",
      "Epoch 83/100\n",
      "104/104 [==============================] - 53s 514ms/step - loss: 5.3940e-05\n",
      "Epoch 84/100\n",
      "104/104 [==============================] - 59s 563ms/step - loss: 7.9189e-05\n",
      "Epoch 85/100\n",
      "104/104 [==============================] - 52s 501ms/step - loss: 4.7950e-05\n",
      "Epoch 86/100\n",
      "104/104 [==============================] - 57s 549ms/step - loss: 4.6148e-05\n",
      "Epoch 87/100\n",
      "104/104 [==============================] - 56s 529ms/step - loss: 6.5529e-05\n",
      "Epoch 88/100\n",
      "104/104 [==============================] - 56s 535ms/step - loss: 6.2057e-05\n",
      "Epoch 89/100\n",
      "104/104 [==============================] - 49s 473ms/step - loss: 5.3816e-05\n",
      "Epoch 90/100\n",
      "104/104 [==============================] - 49s 475ms/step - loss: 7.0899e-05\n",
      "Epoch 91/100\n",
      "104/104 [==============================] - 46s 447ms/step - loss: 4.9289e-05\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 43s 411ms/step - loss: 5.1918e-05\n",
      "Epoch 93/100\n",
      "104/104 [==============================] - 46s 447ms/step - loss: 4.9416e-05\n",
      "Epoch 94/100\n",
      "104/104 [==============================] - 41s 399ms/step - loss: 6.1451e-05\n",
      "Epoch 95/100\n",
      "104/104 [==============================] - 43s 412ms/step - loss: 5.1122e-05\n",
      "Epoch 96/100\n",
      "104/104 [==============================] - 40s 390ms/step - loss: 5.7554e-05\n",
      "Epoch 97/100\n",
      "104/104 [==============================] - 35s 340ms/step - loss: 4.9107e-05\n",
      "Epoch 98/100\n",
      "104/104 [==============================] - 39s 373ms/step - loss: 4.9410e-05\n",
      "Epoch 99/100\n",
      "104/104 [==============================] - 41s 388ms/step - loss: 6.1737e-05\n",
      "Epoch 100/100\n",
      "104/104 [==============================] - 45s 434ms/step - loss: 4.9254e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAj30lEQVR4nO3de5xV1X338c+PGRhuIjgDKDcBQ0QERBxRkSiYxgKmYhJNsFgRzSPeYoK1QWybS9Mm1rbJI694qRqi1FSjiSb0CUqVR+SJFmVQMRJFCaAOoFyUAeQOv+ePted+5px9YDb7MPN9v177NefstdbZv3XOmfPba1/N3REREYmrTdoBiIjI0UWJQ0RE8qLEISIieVHiEBGRvChxiIhIXorTDuBIKCsr8/79+6cdhojIUWXZsmWb3b17w/mtInH079+fioqKtMMQETmqmNl7meZrU5WIiORFiUNERPKixCEiInlpFfs4RKSw7Nu3j8rKSnbv3p12KAK0b9+ePn360LZt21j1lThE5IirrKzkmGOOoX///phZ2uG0au7Oli1bqKysZMCAAbHaaFOViBxxu3fvprS0VEmjAJgZpaWleY3+lDhEJBVKGoUj389CiUNERPKixJHNXXfBRRelHYWINLMtW7YwYsQIRowYwfHHH0/v3r1rnu/duzdr24qKCm6++eacyxg9enSzxLpo0SK++MUvNstrNRftHM9mzRp48cW0oxCRZlZaWsrrr78OwPe+9z06d+7MrbfeWlO+f/9+iosz/zyWl5dTXl6ecxkvvfRSs8RaiDTiyKa4GPbvTzsKETkCrrrqKm655RbGjRvHzJkzeeWVVxg9ejSnn346o0ePZuXKlUD9EcD3vvc9rr76asaOHcvAgQOZPXt2zet17ty5pv7YsWO59NJLGTx4MFOmTKH6zqvz589n8ODBjBkzhptvvjmvkcWjjz7KsGHDGDp0KDNnzgTgwIEDXHXVVQwdOpRhw4bxk5/8BIDZs2czZMgQhg8fzuTJkw/7vdKIIxslDpEjY+zYxvO++lW44QbYuRMmTmxcftVVYdq8GS69tH7ZokWHFMY777zDc889R1FREdu2bWPx4sUUFxfz3HPPcfvtt/PrX/+6UZu3336b559/nu3bt3PyySdz/fXXNzof4rXXXmPFihX06tWLc889lxdffJHy8nKmT5/O4sWLGTBgAJdffnnsONevX8/MmTNZtmwZ3bp148ILL+Q3v/kNffv2Zd26dbz55psAbN26FYA77riDNWvWUFJSUjPvcGjEkY0Sh0irctlll1FUVARAVVUVl112GUOHDmXGjBmsWLEiY5uLLrqIkpISysrK6NGjBx999FGjOqNGjaJPnz60adOGESNGsHbtWt5++20GDhxYc+5EPolj6dKljB07lu7du1NcXMyUKVNYvHgxAwcOZPXq1XzjG9/gmWeeoUuXLgAMHz6cKVOm8MgjjzS5CS4fGnFk07cvjBwJ7qBDB0WSk22E0LFj9vKyskMeYTTUqVOnmsd///d/z7hx43jqqadYu3YtYzONioCSkpKax0VFRezPsLKZqU715qpD0VTbbt26sXz5chYsWMDdd9/N448/zpw5c/jd737H4sWLmTdvHj/4wQ9YsWLFYSUQjTiymT4dXnlFSUOkFaqqqqJ3794APPTQQ83++oMHD2b16tWsXbsWgF/+8pex25511lm88MILbN68mQMHDvDoo49y/vnns3nzZg4ePMhXvvIVfvCDH/Dqq69y8OBBPvjgA8aNG8edd97J1q1b2bFjx2HFrhGHiEgG3/72t5k6dSo//vGPueCCC5r99Tt06MA999zD+PHjKSsrY9SoUU3WXbhwIX369Kl5/sQTT/CjH/2IcePG4e5MnDiRSZMmsXz5cqZNm8bBgwcB+NGPfsSBAwe44oorqKqqwt2ZMWMGXbt2PazY7XCGS0eL8vJyP6QbOf3Hf8C//Vs4JLfOEFZEDs9bb73FKaecknYYqduxYwedO3fG3bnxxhsZNGgQM2bMSCWWTJ+JmS1z90bHHmtTVTZbtsDy5bBvX9qRiEgL9MADDzBixAhOPfVUqqqqmD59etohxaJNVdlU7zzSkVUikoAZM2akNsI4HImOOMxsvJmtNLNVZnZbhnIzs9lR+RtmNrJO2Rwz22hmbzZoc5yZPWtm70Z/uyXWASUOkcS0hs3kR4t8P4vEEoeZFQF3AxOAIcDlZjakQbUJwKBouha4t07ZQ8D4DC99G7DQ3QcBC6PnyVDiEElE+/bt2bJli5JHAai+H0f79u1jt0lyU9UoYJW7rwYws8eAScAf69SZBMz18O1ZYmZdzewEd9/g7ovNrH+G150EjI0ePwwsAmYm0oPeveGCC2oTiIg0iz59+lBZWcmmTZvSDkWovQNgXEn+IvYGPqjzvBI4K0ad3sCGLK/b0903ALj7BjPr0QyxZjZhQphEpFm1bds29t3mpPAkuY8j01lzDcelceoc2sLNrjWzCjOr0FqNiEjzSTJxVAJ96zzvA6w/hDoNfWRmJwBEfzdmquTu97t7ubuXd+/ePa/AayxYACedBG+/fWjtRURaoCQTx1JgkJkNMLN2wGRgXoM684Aro6OrzgaqqjdDZTEPmBo9ngr8tjmDrmf3bli9GnbtSmwRIiJHm8QSh7vvB24CFgBvAY+7+wozu87MrouqzQdWA6uAB4Abqtub2aPA/wAnm1mlmV0TFd0BfMHM3gW+ED1Pho6qEhFpJNHDhdx9PiE51J13X53HDtzYRNuM1xh29y3A55sxzKYpcYiINKJLjmSjxCEi0ogSRzY9esDFF0O35E5OFxE52ujMtmyGDYPfJrfvXUTkaKQRh4iI5EWJI5s33oCePeGZZ9KORESkYChxZOMOGzfqPA4RkTqUOLKpPqpKN3ISEamhxJFN27bhrw7HFRGpocSRjc7jEBFpRIkjmy5dYMoU6N8/7UhERAqGzuPIpqwMHnkk7ShERAqKRhwiIpIXJY5sPv4YOnaEu+9OOxIRkYKhxJFNUVE4h2PPnrQjEREpGEoc2ehwXBGRRpQ4stHhuCIijShxZKPEISLSiBJHNm3awPTpMHJk2pGIiBQMnceRy3335a4jItKKaMSRy8GDcOBA2lGIiBQMJY5cunaFW29NOwoRkYKhxJFLcbF2jouI1KHEkYsSh4hIPUocuRQXax+HiEgdShy5aMQhIlKPDsfN5frr4aST0o5CRKRgKHHkMmtW2hGIiBQUbarKZfv2MImICJBw4jCz8Wa20sxWmdltGcrNzGZH5W+Y2chcbc1shJktMbPXzazCzEYl2QfGjIErr0x0ESIiR5PEEoeZFQF3AxOAIcDlZjakQbUJwKBouha4N0bbO4Hvu/sI4DvR8+Ro57iISD1JjjhGAavcfbW77wUeAyY1qDMJmOvBEqCrmZ2Qo60DXaLHxwLrE+yDEoeISANJ7hzvDXxQ53klcFaMOr1ztP0WsMDM/pWQ+EZnWriZXUsYxdCvX79D6gCgxCEi0kCSIw7LMM9j1snW9npghrv3BWYAP8u0cHe/393L3b28e/fuMUPOoLgY9u079PYiIi1MkiOOSqBvned9aLxZqak67bK0nQp8M3r8BPBgM8Wb2TXXgDfMdyIirVeSI46lwCAzG2Bm7YDJwLwGdeYBV0ZHV50NVLn7hhxt1wPnR48vAN5NsA/hiKqpUxNdhIjI0SSxEYe77zezm4AFQBEwx91XmNl1Ufl9wHxgIrAK2AlMy9Y2eun/BdxlZsXAbqL9GInZvDlsqjrhhEQXIyJytDBvBZthysvLvaKi4tAaX3IJrF0Lr7/ejBGJiBQ+M1vm7uUN5+vM8Vx0VJWISD1KHLkocYiI1KPEkYsSh4hIPUocuShxiIjUo8uq5/KXfwnnnZd2FCIiBUOJI5cLL0w7AhGRgqJNVbl8+CG89VbaUYiIFAwljlzuuAPOOSftKERECoYSRy7aOS4iUo8SRy5KHCIi9Shx5KLEISJSjxJHLsXFcOCALq0uIhLR4bi5XHwxnHhiSByW6f5SIiKtixJHLiNHhklERABtqsrtww9hyRLt5xARiShx5PLYY+E8ju3b045ERKQgKHHkUhxtzdOIQ0QEUOLIrW3b8FeJQ0QEUOLITSMOEZF6lDhyUeIQEalHiSOX88+Hxx+H7t3TjkREpCDoPI5c+vcPk4iIABpx5LZpEzz7LGzblnYkIiIFQYkjl5deCncBXLUq7UhERAqCEkcu2jkuIlKPEkcuShwiIvUoceRSnTgOHEg3DhGRAqHEkYtGHCIi9SSaOMxsvJmtNLNVZnZbhnIzs9lR+RtmNjJOWzP7RlS2wszuTLIPDBsGTz8Nw4cnuhgRkaNFYudxmFkRcDfwBaASWGpm89z9j3WqTQAGRdNZwL3AWdnamtk4YBIw3N33mFmPpPoAwHHHwfjxiS5CRORokuSIYxSwyt1Xu/te4DHCD35dk4C5HiwBuprZCTnaXg/c4e57ANx9Y4J9gKoqeOopWL8+0cWIiBwtkkwcvYEP6jyvjObFqZOt7WeBz5nZy2b2gpmdmWnhZnatmVWYWcWmTZsOvRfvvQdf/nK4mZOIiCSaODLdoNtj1snWthjoBpwN/A3wuFnjm4G7+/3uXu7u5d0P5zpT2jkuIlJPkteqqgT61nneB2i4vaepOu2ytK0EnnR3B14xs4NAGXAYw4oslDhEROqJNeIws05m1iZ6/Fkzu9jM2uZothQYZGYDzKwdMBmY16DOPODK6Oiqs4Eqd9+Qo+1vgAuqYyEkmc1x+nFIlDhEROqJO+JYTNiv0A1YCFQAXwOmNNXA3feb2U3AAqAImOPuK8zsuqj8PmA+MBFYBewEpmVrG730HGCOmb0J7AWmRqOPZFQnjn37EluEiMjRxOL85prZq+4+0sy+AXRw9zvN7DV3Pz35EA9feXm5V1RUHFrjPXugogI+8xno2bN5AxMRKWBmtszdyxvOjzviMDM7hzDCuCbPtke3khI499y0oxARKRhxj6r6FjALeCra3DQQeD6xqArJ3r0wdy6sWJG7rohIKxArcbj7C+5+sbv/c7STfLO735xwbIVh926YOhUWLEg7EhGRghD3qKr/NLMuZtYJ+COw0sz+JtnQCoSOqhIRqSfupqoh7r4NuIRwJFQ/4K+SCqqg6KgqEZF64iaOttF5G5cAv3X3fTQ+C7xl0ohDRKSeuInj34G1QCdgsZmdCGxLKqiC0qZNmJQ4RESAmIfUuvtsYHadWe9FlzdvHV57TedwiIhEYiUOMzsW+C5wXjTrBeAfgKqE4iosuomTiEiNuJuq5gDbga9G0zbg50kFVXAefBAWL047ChGRghA3cZzk7t+Nbqy02t2/DwxMMrCCMnMmPPFE2lGIiBSEuIljl5mNqX5iZucCu5IJqQAVF2vnuIhIJO71pq4D5kb7OgA+AaYmE1IBUuIQEakR96iq5cBpZtYler7NzL4FvJFgbIVDiUNEpEZet451923RGeQAtyQQT2FS4hARqXE4l0bPdF/wlun556FDh7SjEBEpCIeTOFrHJUcA+vVLOwIRkYKRNXGY2XYyJwgDWs8q+M9/Dp07w2WXpR2JiEjqsiYOdz/mSAVS0H76UzjhBCUOERHy3DnearVtq53jIiIRJY44dFSViEgNJY44lDhERGooccShxCEiUuNwDsdtPX71K7DWc9qKiEg2ShxxdO2adgQiIgVDm6ri+MUv4K670o5CRKQgKHHE8dRT8MADaUchIlIQlDji0M5xEZEaiSYOMxtvZivNbJWZ3Zah3MxsdlT+hpmNzKPtrWbmZlaWZB8AJQ4RkToSSxxmVgTcDUwAhgCXm9mQBtUmAIOi6Vrg3jhtzawv8AXg/aTir0eJQ0SkRpIjjlHAquge5XuBx4BJDepMAuZ6sAToamYnxGj7E+DbHKkr9CpxiIjUSDJx9AY+qPO8MpoXp06Tbc3sYmBddFfCJpnZtWZWYWYVmzZtOrQeVLvnHliz5vBeQ0SkhUgycWQ6Y67hCKGpOhnnm1lH4G+B7+RauLvf7+7l7l7evXv3nMFm1a5duNChiIgkmjgqgb51nvcB1ses09T8k4ABwHIzWxvNf9XMjm/WyBt66im49dZEFyEicrRIMnEsBQaZ2QAzawdMBuY1qDMPuDI6uupsoMrdNzTV1t3/4O493L2/u/cnJJiR7v5hgv2Al16Ce+9NdBEiIkeLxC454u77zewmYAFQBMxx9xVmdl1Ufh8wH5gIrAJ2AtOytU0q1py0c1xEpEai16py9/mE5FB33n11HjtwY9y2Ger0P/woY1DiEBGpoTPH4yguhoMHwyQi0sopccTRtm04surAgbQjERFJnRJHHLffDnv26JBcERGUOEREJE9KHHE89xxMnQo7dqQdiYhI6pQ44li5EubOhV270o5ERCR1ShxxFEdHLeuQXBERJY5YqhPHvn3pxiEiUgCUOOLQiENEpIYSRxwdO0JpKfiRuf2HiEghU+KI47LLYPNmOOmktCMREUmdEoeIiORFiSOOpUvhy1+GP/0p7UhERFKnxBHHxo3hZk4ff5x2JCIiqVPiiEOH44qI1FDiiKP64oY6HFdERIkjFp3HISJSQ4kjjo4d4cQTdVl1ERESvnVsi1FeDmvXph2FiEhB0IhDRETyosQRx5o1cOGFsHhx2pGIiKROiSOOXbvg2Wfhww/TjkREJHVKHHHoqCoRkRpKHHEocYiI1FDiiEOJQ0SkhhJHHO3bw9Ch0KVL2pGIiKRO53HE0aMH/OEPaUchIlIQNOIQEZG8JJo4zGy8ma00s1VmdluGcjOz2VH5G2Y2MldbM/sXM3s7qv+UmXVNsg8A7NwJ55wDv/hF4osSESl0iSUOMysC7gYmAEOAy81sSINqE4BB0XQtcG+Mts8CQ919OPAOMCupPtQwgyVLoLIy8UWJiBS6JEcco4BV7r7a3fcCjwGTGtSZBMz1YAnQ1cxOyNbW3f/b3asPb1oC9EmwD4GOqhIRqZFk4ugNfFDneWU0L06dOG0BrgaezrRwM7vWzCrMrGLTpk15ht5AUVH4q8QhIpJo4rAM8zxmnZxtzexvgf1Axh0P7n6/u5e7e3n37t1jhJtFmzZhUuIQEUn0cNxKoG+d532A9THrtMvW1symAl8EPu/uDZNRMs49F3pnGvSIiLQuSSaOpcAgMxsArAMmA3/ZoM484CYzeww4C6hy9w1mtqmptmY2HpgJnO/uOxOMvz5dGVdEBEgwcbj7fjO7CVgAFAFz3H2FmV0Xld8HzAcmAquAncC0bG2jl/4pUAI8a2YAS9z9uqT6ISIi9dmR2tKTpvLycq+oqDi8F/nc5+DP/xz+7u+aJygRkQJnZsvcvbzhfJ05Hte778K6dWlHISKSOiWOuIqLdVSViAhKHPEpcYiIAEoc8RUXw759aUchIpI6XVY9rvPOg89+Nu0oRERSp8QR15w5aUcgIlIQtKlKRETyosQR11/8BUydmnYUIiKp06aquDZt0s5xERE04ohPh+OKiABKHPEpcYiIAEoc8SlxiIgA2scR33nnwZ49aUchIpI6JY64vvOdtCMQESkI2lQlIiJ5UeKIa9o0OOectKMQEUmdEkdcu3bBxx+nHYWISOqUOOLSUVUiIoASR3xt2ypxiIigxBGfRhwiIoAOx41vzBjo1CntKEREUqfEEdfUqbo6rogI2lQlIiJ5UuKIa9YsOOaYtKMQEUmdEkc+9u5NOwIRkdQpccTVsWNIHH/2Z/Dww7BzZ9oRiYikQokjrhtvDBc6XLMGrrkGduwI8z/6CA4eTDc2EZEjyNw97RgSV15e7hUVFc3zYu7w9ttwyinh+bhx8M47cO65cOaZMGIE9O4NQ4aE8t//vvZy7H37woAB4WRCiW//fli+HAYP1iHRIkeQmS1z9/KG8xM9HNfMxgN3AUXAg+5+R4Nyi8onAjuBq9z91Wxtzew44JdAf2At8FV3/yTJftRjVps0AK67Dp58El55BZ54Isz70pfCPIBLLoEtW2rrFxfDDTfAXXeF53/912H08vHHYdq7F664AqZPDwnnppvg+OPDjnmzMI0bB2ecAevXw/e/D8ceC126hDrt2sH554fEVVUFL74IRUVh09qOHeHv5z8Pn/kMbNwIzz0HPXpAWVn4gd65E4YOheOOgz/9CZ5+Gt59F1asCAmzXz/42c/Ce7B1a7gX+44dsG5dqL9xI/zTP4W+ffwx7N4Na9fC6tWwbRv06hXeEwgJd8+eEN/evaFuSQmcfnooX7cuLOuBB6CyEjp0gNmz4etfh+3b4YMPQp83b4b33w/1L7oITjwRPvkkvP7+/WFq0yYk7GHDQvJ58cXwee3eHRJ6v34htjFjQgzbtsGnn4Y43MOo0h369Amfwauvhtfv1Sssr3fvML+oqDb29evDe9SxY3g/e/SA0tLwOuXlIa4zzghTWVmIY/To0P6998JrFheH+tu3h9c/5pjwfM0aeOutMK1aBR9+GA4X/9KXQuw//SkMHw4nnxxWVorr/Kvv2hXen5KS2isi7NkTYiwpCf3esiW838ccE+aZZf+/OHiw9vu5YkX4f/j44/A6+/aFvl19NXTuHEbp27eHmHbtCt+5PXvCRUTNwnt28GCo265d6O/+/bUrXFu3hvabN4fX2rABDhwI3wsIfW/fHiZODJ9PPvbvh2XLYOXK8PpDhoSVweOPb1xvw4bwGQMMHAjdu4e+VlWF79gnn4TyDRvgtNPCdyyXPXtCn/bvh65dw/92UVF4D8xq97O2a5e5fVVV+B889tjweRYn9BPv7olMhB/8PwEDgXbAcmBIgzoTgacBA84GXs7VFrgTuC16fBvwz7liOeOMM/yI2LjRfdEi9+XLa+e9+KL74sVh/kMPuc+a5f7oo6Fs5073Ll3ce/RwP+UU93PPdb/gAvcHHgjlGza4H3+8e5s27uGrE6Yf/jCUv/deaNuhQ/3yf//3UL50af351dN//mcoX7Agc/nTT4fyJ58Mzzt1cj/zTPcrrnA/+2z3Tz4J5bfe2rhtly7uu3eH8smTG5cPHlz73owZ07j8zDNry0eMCPMuvNB9zhz3G25wf+mlUPb005lj//3vQ/ncuZnLX3stlN97r3vHju6lpfXLN24M5bNmZW5f3bcbbmhcduyxtbFfemnj8iFDast/+EP38ePdu3evLb/88lB24ECIrW1b927daj//W24J5du313/d0lL3YcPcH344lC9ZUr+8uNj9xBPdFy4M5f/1X5n7tmhRKH/kkcbtO3eufe/mznXv1cu9Z88QX0lJqPfee7V9q25bVFRbvmNHKJ8xo/Gy27RxP3gwlF9zTf32Zu7HHVf73n3lK43b9+pVW37mmbXzu3Z1P+YY96lTa8sHDQr/V2VlIf7OncPn6R7+J80av/6//Esof//9sKyiosz/cxUVmd/bX/86lC9aFP5Hqj/fdu3C/2/1e//QQ43bFhfX/qbce2+Y165d6Fv1tGZNKP+Hf6jf9rbb/HAAFZ7hNzXJEccoYJW7rwYws8eAScAf69SZBMyNAlxiZl3N7ATCaKKptpOAsVH7h4FFwMwE+xFf9+5hbb+u6jVIaFzWoUNYQ2jK8cfXrk3t3l37dSgpCeX9+oW1EwhrIp9+GtZYqg8bPuUUePnlsBbUqVNYg6te+wX43OfCGutHH4W1q3btQvmIEaF8/PhQVlYW1tgb+trXQt1OnaBnzzCKKSurXTudMiUsY8CAMHXtWv8uij/8YVg72r8/9KmkJLyH1W66Kdx5cdCg8HzatNqy006Dxx4La9elpWGNtk+f2vbnnQfz54c1ruo1tr17w5ohhP1U06eHWHfuDCOaDz+sfW8uuSSMJKq1aRPqVq/B3X57GDmuXx9GB5WVYS232i23hBHAscfWXlm5qip8lkVF4fDuWbNCXOvWhX506xbaHjgA99wTPpsdO8L8rl1rL+vfrl0YhZ1ySpiqY6521llhWW++GUZF77wTRmTVm/mGDYP77gvvx969oU8lJeHzAzj7bHjwwRD39u1h2r279r3t1y+szVeP4jp1Ct+b6rXgr389fDdKS8NIGML3q3r5V1wBI0eGZXfsWDvV/d4MGxb6/umnIb7OnWv7N316+G6Wlob/kZ49w2df7eWXQ99/97vw+RQV1Y5iASZMCH1r2za8dnFx6DOE/8lnngmf/XHHhdHT8uVw6qmhvKQkLLtXr9pRqlkYpUMYJc6eXfu59eoVYhw8OJR36hRGXtXLhfD9r45/zJjw3hcVhc9w69bwP1NaGsrPPBP+8R/D92XnztpRXvX786UvQf/+oe2WLYndCiKxfRxmdikw3t2/Hj3/K+Asd7+pTp3/A9zh7r+Pni8kJIH+TbU1s63u3rXOa3zi7t0yLP9a4FqAfv36nfHee+8l0k8RkZaqqX0cSR5VlWmjaMMs1VSdOG2zcvf73b3c3cu7112LFRGRw5Jk4qgE+tZ53gdYH7NOtrYfRZuziP5ubMaYRUQkhyQTx1JgkJkNMLN2wGRgXoM684ArLTgbqHL3DTnazgOmRo+nAr9NsA8iItJAYjvH3X2/md0ELCAcJTXH3VeY2XVR+X3AfMKRVasIh+NOy9Y2euk7gMfN7BrgfeCypPogIiKN6QRAERHJKI2d4yIi0gIpcYiISF6UOEREJC+tYh+HmW0C8jkDsAzYnFA4haw19rs19hlaZ79bY5/h8Pp9ors3OhGuVSSOfJlZRaYdQi1da+x3a+wztM5+t8Y+QzL91qYqERHJixKHiIjkRYkjs/vTDiAlrbHfrbHP0Dr73Rr7DAn0W/s4REQkLxpxiIhIXpQ4REQkL0ocDZjZeDNbaWarzOy2tONJgpn1NbPnzewtM1thZt+M5h9nZs+a2bvR30Y3yDramVmRmb0W3USstfS5q5n9yszejj7zc1p6v81sRvTdftPMHjWz9i2xz2Y2x8w2mtmbdeY12U8zmxX9tq00sz8/1OUqcdRhZkXA3cAEYAhwuZkNSTeqROwH/trdTyHc6/3GqJ+3AQvdfRCwMHre0nwTeKvO89bQ57uAZ9x9MHAaof8ttt9m1hu4GSh396GEK2xPpmX2+SFgfIN5GfsZ/Y9PBk6N2twT/eblTYmjvpr7pLv7XqD6XuctirtvcPdXo8fbCT8kvQl9fTiq9jBwSSoBJsTM+gAXAQ/Wmd3S+9wFOA/4GYC773X3rbTwfhNuGdHBzIqBjoQbwbW4Prv7YuDjBrOb6uck4DF33+Puawi3sxh1KMtV4qivN/BBneeV0bwWy8z6A6cDLwM9oxtpEf3tkWJoSfjfwLeBg3XmtfQ+DwQ2AT+PNtE9aGadaMH9dvd1wL8S7tezgXCDuP+mBfe5gab62Wy/b0oc9R32vc6PJmbWGfg18C1335Z2PEkysy8CG919WdqxHGHFwEjgXnc/HfiUlrGJpknRNv1JwACgF9DJzK5IN6qC0Gy/b0oc9cW5T3qLYGZtCUnjF+7+ZDS7Jd/P/VzgYjNbS9gEeYGZPULL7jOE73Slu78cPf8VIZG05H7/GbDG3Te5+z7gSWA0LbvPdTXVz2b7fVPiqC/OfdKPemZmhG3eb7n7j+sUtdj7ubv7LHfv4+79CZ/r/3X3K2jBfQZw9w+BD8zs5GjW54E/0rL7/T5wtpl1jL7rnyfsx2vJfa6rqX7OAyabWYmZDQAGAa8cygJ05ngDZjaRsC28+l7n/5RuRM3PzMYA/w/4A7Xb+28n7Od4HOhHdD93d2+44+2oZ2ZjgVvd/YtmVkoL77OZjSAcENAOWA1MI6w0tth+m9n3ga8RjiB8Dfg60JkW1mczexQYS7h0+kfAd4Hf0EQ/zexvgasJ78u33P3pQ1quEoeIiORDm6pERCQvShwiIpIXJQ4REcmLEoeIiORFiUNERPKixCHSDMzsgJm9XmdqtrOzzax/3aufiqStOO0ARFqIXe4+Iu0gRI4EjThEEmRma83sn83slWj6TDT/RDNbaGZvRH/7RfN7mtlTZrY8mkZHL1VkZg9E95j4bzPrkFqnpNVT4hBpHh0abKr6Wp2ybe4+Cvgp4aoERI/nuvtw4BfA7Gj+bOAFdz+NcE2pFdH8QcDd7n4qsBX4SqK9EclCZ46LNAMz2+HunTPMXwtc4O6rowtLfujupWa2GTjB3fdF8ze4e5mZbQL6uPueOq/RH3g2ujEPZjYTaOvu/3gEuibSiEYcIsnzJh43VSeTPXUeH0D7JyVFShwiyftanb//Ez1+iXCVXoApwO+jxwuB66Hm/uhdjlSQInFprUWkeXQws9frPH/G3asPyS0xs5cJK2qXR/NuBuaY2d8Q7tA3LZr/TeB+M7uGMLK4nnAXO5GCoX0cIgmK9nGUu/vmtGMRaS7aVCUiInnRiENERPKiEYeIiORFiUNERPKixCEiInlR4hARkbwocYiISF7+P8sjaCo+WVzNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Initialize RNN:\n",
    "regressor = Sequential()\n",
    "\n",
    "#Adding the first RNN layer and some Dropout regularization\n",
    "regressor.add(SimpleRNN(units = 50, activation='tanh', return_sequences=True, input_shape= (x_train.shape[1],1)))\n",
    "regressor.add(Conv1D(filters=300, kernel_size=3 , padding='same', activation='relu', name='Conv1D'))\n",
    "regressor.add(MaxPooling1D(pool_size=1,name='MaxPooling1D'))\n",
    "\n",
    "\n",
    "#Adding the second RNN layer and some Dropout regularization\n",
    "regressor.add(Bidirectional(LSTM(units=50, return_sequences=False)))\n",
    "regressor.add(Dense(1))\n",
    "# Compile the model\n",
    "regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = regressor.fit(x_train, y_train, batch_size=64, epochs=100)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1728411990849783"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the models predicted price values \n",
    "predictions = regressor.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions - y_test) ** 2)))\n",
    "rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-5742caf560dd>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_3['Predictions'] = predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1984692988434668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "train = data[:training_data_len]\n",
    "valid_3 = data[training_data_len:]\n",
    "valid_3['Predictions'] = predictions\n",
    "\n",
    "mape(valid_3['Close'], valid_3['Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
