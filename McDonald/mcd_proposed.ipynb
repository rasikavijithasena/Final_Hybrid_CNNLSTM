{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-24 14:30:00-04:00</td>\n",
       "      <td>244.699997</td>\n",
       "      <td>244.809998</td>\n",
       "      <td>244.639999</td>\n",
       "      <td>244.699997</td>\n",
       "      <td>244.699997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-24 14:31:00-04:00</td>\n",
       "      <td>244.744995</td>\n",
       "      <td>244.744995</td>\n",
       "      <td>244.470001</td>\n",
       "      <td>244.690002</td>\n",
       "      <td>244.690002</td>\n",
       "      <td>7992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-24 14:32:00-04:00</td>\n",
       "      <td>244.740005</td>\n",
       "      <td>244.990005</td>\n",
       "      <td>244.660004</td>\n",
       "      <td>244.862000</td>\n",
       "      <td>244.862000</td>\n",
       "      <td>7028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-24 14:33:00-04:00</td>\n",
       "      <td>244.923706</td>\n",
       "      <td>245.070007</td>\n",
       "      <td>244.860001</td>\n",
       "      <td>245.035004</td>\n",
       "      <td>245.035004</td>\n",
       "      <td>5297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-24 14:34:00-04:00</td>\n",
       "      <td>245.050003</td>\n",
       "      <td>245.050003</td>\n",
       "      <td>244.850006</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>14413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime        Open        High         Low       Close  \\\n",
       "0  2022-05-24 14:30:00-04:00  244.699997  244.809998  244.639999  244.699997   \n",
       "1  2022-05-24 14:31:00-04:00  244.744995  244.744995  244.470001  244.690002   \n",
       "2  2022-05-24 14:32:00-04:00  244.740005  244.990005  244.660004  244.862000   \n",
       "3  2022-05-24 14:33:00-04:00  244.923706  245.070007  244.860001  245.035004   \n",
       "4  2022-05-24 14:34:00-04:00  245.050003  245.050003  244.850006  245.000000   \n",
       "\n",
       "    Adj Close  Volume  \n",
       "0  244.699997       0  \n",
       "1  244.690002    7992  \n",
       "2  244.862000    7028  \n",
       "3  245.035004    5297  \n",
       "4  245.000000   14413  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load local .csv file as DataFrame\n",
    "df = pd.read_csv('mcd_merge.csv')\n",
    "# Inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Datetime'].str[:-6]\n",
    "df['Date']=pd.to_datetime(df[\"Date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "data_date = df.filter(['Date'])\n",
    "\n",
    "data_date = data_date.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_date = int(np.ceil( len(data_date) * .95 ))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_data_date = data_date[0:int(training_data_date), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.56458207, 0.5641259 , 0.57197607, 0.57987219, 0.57827458,\n",
      "       0.57873074, 0.57416703, 0.57804615, 0.57599238, 0.57485163,\n",
      "       0.57188483, 0.56823345, 0.56663584, 0.55682314, 0.55408477,\n",
      "       0.55545395, 0.54815119, 0.54130528, 0.53263333, 0.5248744 ,\n",
      "       0.51939767, 0.52441824, 0.53035113, 0.53217717, 0.52898194,\n",
      "       0.52122302, 0.52692817, 0.53308949, 0.54404364, 0.54187565,\n",
      "       0.53354635, 0.55134641, 0.56047452, 0.57325401, 0.56640811,\n",
      "       0.57827458, 0.56366905, 0.5595615 , 0.5618437 , 0.56047452,\n",
      "       0.56672707, 0.56047452, 0.56321288, 0.56047452, 0.56093068,\n",
      "       0.56001836, 0.56275672, 0.56229986, 0.56376097, 0.55819232,\n",
      "       0.54952037, 0.55317175, 0.56344131, 0.56458207, 0.56229986,\n",
      "       0.55317175, 0.55088955, 0.55864918, 0.55499779, 0.56823345])]\n",
      "[0.5750793582256062]\n",
      "\n",
      "[array([0.56458207, 0.5641259 , 0.57197607, 0.57987219, 0.57827458,\n",
      "       0.57873074, 0.57416703, 0.57804615, 0.57599238, 0.57485163,\n",
      "       0.57188483, 0.56823345, 0.56663584, 0.55682314, 0.55408477,\n",
      "       0.55545395, 0.54815119, 0.54130528, 0.53263333, 0.5248744 ,\n",
      "       0.51939767, 0.52441824, 0.53035113, 0.53217717, 0.52898194,\n",
      "       0.52122302, 0.52692817, 0.53308949, 0.54404364, 0.54187565,\n",
      "       0.53354635, 0.55134641, 0.56047452, 0.57325401, 0.56640811,\n",
      "       0.57827458, 0.56366905, 0.5595615 , 0.5618437 , 0.56047452,\n",
      "       0.56672707, 0.56047452, 0.56321288, 0.56047452, 0.56093068,\n",
      "       0.56001836, 0.56275672, 0.56229986, 0.56376097, 0.55819232,\n",
      "       0.54952037, 0.55317175, 0.56344131, 0.56458207, 0.56229986,\n",
      "       0.55317175, 0.55088955, 0.55864918, 0.55499779, 0.56823345]), array([0.5641259 , 0.57197607, 0.57987219, 0.57827458, 0.57873074,\n",
      "       0.57416703, 0.57804615, 0.57599238, 0.57485163, 0.57188483,\n",
      "       0.56823345, 0.56663584, 0.55682314, 0.55408477, 0.55545395,\n",
      "       0.54815119, 0.54130528, 0.53263333, 0.5248744 , 0.51939767,\n",
      "       0.52441824, 0.53035113, 0.53217717, 0.52898194, 0.52122302,\n",
      "       0.52692817, 0.53308949, 0.54404364, 0.54187565, 0.53354635,\n",
      "       0.55134641, 0.56047452, 0.57325401, 0.56640811, 0.57827458,\n",
      "       0.56366905, 0.5595615 , 0.5618437 , 0.56047452, 0.56672707,\n",
      "       0.56047452, 0.56321288, 0.56047452, 0.56093068, 0.56001836,\n",
      "       0.56275672, 0.56229986, 0.56376097, 0.55819232, 0.54952037,\n",
      "       0.55317175, 0.56344131, 0.56458207, 0.56229986, 0.55317175,\n",
      "       0.55088955, 0.55864918, 0.55499779, 0.56823345, 0.57507936])]\n",
      "[0.5750793582256062, 0.5654950852918095]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "\n",
    "#changes scaled_data to dataset\n",
    "train_data = scaled_data[0:int(training_data_len), :] \n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "413/413 [==============================] - 16s 32ms/step - loss: 0.0058\n",
      "Epoch 2/100\n",
      "413/413 [==============================] - 18s 43ms/step - loss: 0.0016\n",
      "Epoch 3/100\n",
      "413/413 [==============================] - 13s 31ms/step - loss: 8.4056e-04\n",
      "Epoch 4/100\n",
      "413/413 [==============================] - 17s 40ms/step - loss: 6.8858e-04\n",
      "Epoch 5/100\n",
      "413/413 [==============================] - 29s 70ms/step - loss: 5.1701e-04\n",
      "Epoch 6/100\n",
      "413/413 [==============================] - 34s 83ms/step - loss: 4.1071e-04\n",
      "Epoch 7/100\n",
      "413/413 [==============================] - 46s 111ms/step - loss: 3.8163e-04\n",
      "Epoch 8/100\n",
      "413/413 [==============================] - 37s 90ms/step - loss: 2.8470e-04\n",
      "Epoch 9/100\n",
      "413/413 [==============================] - 45s 108ms/step - loss: 3.1499e-04\n",
      "Epoch 10/100\n",
      "413/413 [==============================] - 37s 89ms/step - loss: 3.2249e-04\n",
      "Epoch 11/100\n",
      "413/413 [==============================] - 38s 91ms/step - loss: 2.5906e-04\n",
      "Epoch 12/100\n",
      "413/413 [==============================] - 35s 85ms/step - loss: 2.5557e-04\n",
      "Epoch 13/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.8667e-04\n",
      "Epoch 14/100\n",
      "413/413 [==============================] - 34s 83ms/step - loss: 2.9302e-04\n",
      "Epoch 15/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.4469e-04\n",
      "Epoch 16/100\n",
      "413/413 [==============================] - 39s 94ms/step - loss: 2.6634e-04\n",
      "Epoch 17/100\n",
      "413/413 [==============================] - 33s 80ms/step - loss: 2.2733e-04\n",
      "Epoch 18/100\n",
      "413/413 [==============================] - 34s 84ms/step - loss: 2.1935e-04\n",
      "Epoch 19/100\n",
      "413/413 [==============================] - 39s 94ms/step - loss: 2.3112e-04\n",
      "Epoch 20/100\n",
      "413/413 [==============================] - 40s 97ms/step - loss: 2.5964e-04\n",
      "Epoch 21/100\n",
      "413/413 [==============================] - 34s 83ms/step - loss: 2.5933e-04\n",
      "Epoch 22/100\n",
      "413/413 [==============================] - 35s 84ms/step - loss: 2.2011e-04\n",
      "Epoch 23/100\n",
      "413/413 [==============================] - 34s 81ms/step - loss: 2.1863e-04\n",
      "Epoch 24/100\n",
      "413/413 [==============================] - 39s 95ms/step - loss: 2.2382e-04\n",
      "Epoch 25/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.5841e-04\n",
      "Epoch 26/100\n",
      "413/413 [==============================] - 34s 81ms/step - loss: 2.1570e-04\n",
      "Epoch 27/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.3465e-04\n",
      "Epoch 28/100\n",
      "413/413 [==============================] - 32s 77ms/step - loss: 2.0652e-04\n",
      "Epoch 29/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.3783e-04\n",
      "Epoch 30/100\n",
      "413/413 [==============================] - 33s 81ms/step - loss: 2.3002e-04\n",
      "Epoch 31/100\n",
      "413/413 [==============================] - 38s 92ms/step - loss: 2.1440e-04\n",
      "Epoch 32/100\n",
      "413/413 [==============================] - 36s 86ms/step - loss: 2.2334e-04\n",
      "Epoch 33/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 1.9737e-04\n",
      "Epoch 34/100\n",
      "413/413 [==============================] - 34s 83ms/step - loss: 2.1684e-04\n",
      "Epoch 35/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 2.2267e-04\n",
      "Epoch 36/100\n",
      "413/413 [==============================] - 30s 73ms/step - loss: 2.0205e-04\n",
      "Epoch 37/100\n",
      "413/413 [==============================] - 35s 85ms/step - loss: 2.2165e-04\n",
      "Epoch 38/100\n",
      "413/413 [==============================] - 40s 98ms/step - loss: 2.1586e-04\n",
      "Epoch 39/100\n",
      "413/413 [==============================] - 38s 92ms/step - loss: 2.1136e-04\n",
      "Epoch 40/100\n",
      "413/413 [==============================] - 40s 97ms/step - loss: 2.0412e-04\n",
      "Epoch 41/100\n",
      "413/413 [==============================] - 32s 78ms/step - loss: 2.0460e-04\n",
      "Epoch 42/100\n",
      "413/413 [==============================] - 33s 79ms/step - loss: 2.0378e-04\n",
      "Epoch 43/100\n",
      "413/413 [==============================] - 32s 78ms/step - loss: 1.9783e-04\n",
      "Epoch 44/100\n",
      "413/413 [==============================] - 33s 79ms/step - loss: 1.9753e-04\n",
      "Epoch 45/100\n",
      "413/413 [==============================] - 22s 54ms/step - loss: 2.0597e-04\n",
      "Epoch 46/100\n",
      "413/413 [==============================] - 28s 68ms/step - loss: 2.0917e-04\n",
      "Epoch 47/100\n",
      "413/413 [==============================] - 21s 50ms/step - loss: 2.0106e-04\n",
      "Epoch 48/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.0941e-04\n",
      "Epoch 49/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.8426e-04\n",
      "Epoch 50/100\n",
      "413/413 [==============================] - 28s 68ms/step - loss: 2.0531e-04\n",
      "Epoch 51/100\n",
      "413/413 [==============================] - 24s 58ms/step - loss: 2.0490e-04\n",
      "Epoch 52/100\n",
      "413/413 [==============================] - 25s 59ms/step - loss: 1.9009e-04\n",
      "Epoch 53/100\n",
      "413/413 [==============================] - 25s 60ms/step - loss: 1.9934e-04\n",
      "Epoch 54/100\n",
      "413/413 [==============================] - 23s 56ms/step - loss: 2.1069e-04\n",
      "Epoch 55/100\n",
      "413/413 [==============================] - 27s 66ms/step - loss: 1.9663e-04\n",
      "Epoch 56/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.8923e-04\n",
      "Epoch 57/100\n",
      "413/413 [==============================] - 31s 74ms/step - loss: 1.9440e-04\n",
      "Epoch 58/100\n",
      "413/413 [==============================] - 31s 74ms/step - loss: 1.9465e-04\n",
      "Epoch 59/100\n",
      "413/413 [==============================] - 30s 73ms/step - loss: 1.7887e-04\n",
      "Epoch 60/100\n",
      "413/413 [==============================] - 30s 73ms/step - loss: 1.7936e-04\n",
      "Epoch 61/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 1.8391e-04\n",
      "Epoch 62/100\n",
      "413/413 [==============================] - 24s 57ms/step - loss: 1.8060e-04\n",
      "Epoch 63/100\n",
      "413/413 [==============================] - 28s 68ms/step - loss: 2.0560e-04\n",
      "Epoch 64/100\n",
      "413/413 [==============================] - 29s 70ms/step - loss: 1.8900e-04\n",
      "Epoch 65/100\n",
      "413/413 [==============================] - 24s 57ms/step - loss: 2.0580e-04\n",
      "Epoch 66/100\n",
      "413/413 [==============================] - 28s 69ms/step - loss: 1.8011e-04\n",
      "Epoch 67/100\n",
      "413/413 [==============================] - 28s 68ms/step - loss: 1.9341e-04\n",
      "Epoch 68/100\n",
      "413/413 [==============================] - 22s 53ms/step - loss: 1.9365e-04\n",
      "Epoch 69/100\n",
      "413/413 [==============================] - 29s 69ms/step - loss: 1.8001e-04\n",
      "Epoch 70/100\n",
      "413/413 [==============================] - 24s 59ms/step - loss: 1.7597e-04\n",
      "Epoch 71/100\n",
      "413/413 [==============================] - 31s 75ms/step - loss: 1.9033e-04\n",
      "Epoch 72/100\n",
      "413/413 [==============================] - 26s 63ms/step - loss: 1.8575e-04\n",
      "Epoch 73/100\n",
      "413/413 [==============================] - 28s 67ms/step - loss: 1.8344e-04\n",
      "Epoch 74/100\n",
      "413/413 [==============================] - 26s 63ms/step - loss: 1.9099e-04\n",
      "Epoch 75/100\n",
      "413/413 [==============================] - 30s 72ms/step - loss: 1.8641e-04\n",
      "Epoch 76/100\n",
      "413/413 [==============================] - 24s 57ms/step - loss: 1.8191e-04\n",
      "Epoch 77/100\n",
      "413/413 [==============================] - 19s 46ms/step - loss: 1.7687e-04\n",
      "Epoch 78/100\n",
      "413/413 [==============================] - 19s 46ms/step - loss: 1.7838e-04\n",
      "Epoch 79/100\n",
      "413/413 [==============================] - 19s 47ms/step - loss: 1.8119e-04\n",
      "Epoch 80/100\n",
      "413/413 [==============================] - 25s 60ms/step - loss: 1.7379e-04\n",
      "Epoch 81/100\n",
      "413/413 [==============================] - 37s 89ms/step - loss: 1.8229e-04\n",
      "Epoch 82/100\n",
      "413/413 [==============================] - 39s 95ms/step - loss: 1.8167e-04\n",
      "Epoch 83/100\n",
      "413/413 [==============================] - 37s 88ms/step - loss: 1.7280e-04\n",
      "Epoch 84/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 1.8955e-04\n",
      "Epoch 85/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 1.6917e-04\n",
      "Epoch 86/100\n",
      "413/413 [==============================] - 33s 80ms/step - loss: 1.6744e-04\n",
      "Epoch 87/100\n",
      "413/413 [==============================] - 35s 84ms/step - loss: 1.6661e-04\n",
      "Epoch 88/100\n",
      "413/413 [==============================] - 37s 89ms/step - loss: 1.6742e-04\n",
      "Epoch 89/100\n",
      "413/413 [==============================] - 39s 94ms/step - loss: 1.7780e-04\n",
      "Epoch 90/100\n",
      "413/413 [==============================] - 38s 92ms/step - loss: 1.7836e-04\n",
      "Epoch 91/100\n",
      "413/413 [==============================] - 42s 102ms/step - loss: 1.6148e-04\n",
      "Epoch 92/100\n",
      "413/413 [==============================] - 35s 86ms/step - loss: 1.6360e-04\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413/413 [==============================] - 45s 109ms/step - loss: 1.7906e-04\n",
      "Epoch 94/100\n",
      "413/413 [==============================] - 52s 127ms/step - loss: 1.6511e-04\n",
      "Epoch 95/100\n",
      "413/413 [==============================] - 44s 107ms/step - loss: 1.7079e-04\n",
      "Epoch 96/100\n",
      "413/413 [==============================] - 35s 84ms/step - loss: 1.7528e-04\n",
      "Epoch 97/100\n",
      "413/413 [==============================] - 42s 101ms/step - loss: 1.7128e-04\n",
      "Epoch 98/100\n",
      "413/413 [==============================] - 32s 77ms/step - loss: 1.8729e-04\n",
      "Epoch 99/100\n",
      "413/413 [==============================] - 34s 82ms/step - loss: 1.7109e-04\n",
      "Epoch 100/100\n",
      "413/413 [==============================] - 33s 81ms/step - loss: 1.5784e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape= (x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu' ))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu' ))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, batch_size=16, epochs=100)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15809270458134822"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions3 = model.predict(x_test)\n",
    "predictions3 = scaler.inverse_transform(predictions3)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions3 - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-20d8112ecf7b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_3['Predictions3'] = predictions3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04493420789019809"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "train = data[:training_data_len]\n",
    "valid_3 = data[training_data_len:]\n",
    "valid_3['Predictions3'] = predictions3\n",
    "\n",
    "mape(valid_3['Close'], valid_3['Predictions3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 59, 128)           384       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 29, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 29, 128)           131584    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 29, 64)            49408     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 29, 32)            12416     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 928)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               92900     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,793\n",
      "Trainable params: 286,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
