{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load local .csv file as DataFrame\n",
    "df = pd.read_csv('aapl_all_csv.csv')\n",
    "# Inspect the data\n",
    "df = df[:12000]\n",
    "\n",
    "df['Date'] = df['Datetime'].str[:-6]\n",
    "df['Date']=pd.to_datetime(df[\"Date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "data_date = df.filter(['Date'])\n",
    "\n",
    "data_date = data_date.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_date = int(np.ceil( len(data_date) * .95 ))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler1 = MinMaxScaler(feature_range=(0,1))\n",
    "#scaled_data1 = scaler1.fit_transform(data_date)\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data_date = data_date[0:int(training_data_date), :]\n",
    "\n",
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585])]\n",
      "[0.8192645319337108]\n",
      "\n",
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585]), array([0.81144125, 0.81464378, 0.81855352, 0.81982585, 0.81926453])]\n",
      "[0.8192645319337108, 0.8167762641645444]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(5, len(train_data)):\n",
    "    x_train.append(train_data[i-5:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 6:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "#x_train = np.reshape(x_train, ( x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1\n",
    "n_length = 5\n",
    "n_features = 1\n",
    "n_outputs=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11395, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_train.reshape((x_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "# reshape output into [samples, timesteps, features]\n",
    "train_y = y_train.reshape((y_train.shape[0],1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "713/713 [==============================] - 32s 14ms/step - loss: 0.0111\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 9.5100e-05\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 9.3238e-05\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 9.1388e-05\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 9.5818e-05\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 9.5333e-05\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 8.3979e-05\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 8.1657e-05\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 8.6826e-05\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 7.5938e-05\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 7.0205e-05\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 6.8000e-05\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.4929e-05\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.8529e-05\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.5234e-05\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.9574e-05\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 10s 15ms/step - loss: 6.1559e-05\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.2682e-05\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 6.3180e-05\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.4440e-05\n",
      "Epoch 21/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 6.2181e-05\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.0958e-05\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.8291e-05\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.0453e-05\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.1015e-05\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.1302e-05\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.5204e-05\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.0820e-05\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.1352e-05\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.8726e-05\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.0455e-05\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 6.1438e-05\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 10s 13ms/step - loss: 5.5058e-05\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.8173e-05\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.6562e-05\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.2675e-05\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 10s 15ms/step - loss: 6.0795e-05\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 10s 15ms/step - loss: 5.6850e-05\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.3737e-05\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.0108e-05\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.8169e-05\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.6295e-05\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.7041e-05\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 10s 13ms/step - loss: 6.0917e-05\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.5796e-05\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.4806e-05\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.4453e-05\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.4462e-05\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 10s 14ms/step - loss: 5.9236e-05\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 6.2102e-05\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.5184e-05\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.6806e-05\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 10s 14ms/step - loss: 5.6274e-05\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.3578e-05\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5532e-05\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.3799e-05\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.4956e-05\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.5298e-05\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.9428e-05\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.4741e-05\n",
      "Epoch 61/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.5310e-05\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.6172e-05\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.4999e-05\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.6073e-05\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3444e-05\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.2315e-05\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.5468e-05\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3808e-05\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.7793e-05\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.6036e-05\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.2109e-05\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.4026e-05\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5014e-05\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.5676e-05\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.3137e-05\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.3235e-05\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.3190e-05\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.4515e-05\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.3153e-05\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.2865e-05\n",
      "Epoch 81/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.5601e-05\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3035e-05\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.5168e-05\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 10s 13ms/step - loss: 5.3578e-05\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.5220e-05\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.5392e-05\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.6172e-05\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.1018e-05\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.2684e-05\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.3371e-05\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.1630e-05\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.0996e-05\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 10s 14ms/step - loss: 5.4282e-05\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 5.2818e-05\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.1472e-05\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.4423e-05\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.2566e-05\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.7201e-05\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.2131e-05\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.0707e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhvElEQVR4nO3de5xVdf3v8deHmeEOgjOD4AwwoKOEiChzUNEU8Kh4STQv4QMLtI5iXoqOhdrP87Osn+avrDh5SYvUn6XRzzQeJ9SUU3HUSLHEJLUIKScQgV+ihNxmPueP79qz9wzD3mvDLNZm5v18PPZj9lrf9V3r891zec+67L3M3REREYmrW9oFiIjI/kXBISIiRVFwiIhIURQcIiJSFAWHiIgUpTztAvaFqqoqr6urS7sMEZH9yksvvbTB3avbzu8SwVFXV8eyZcvSLkNEZL9iZn9tb74OVYmISFEUHCIiUhQFh4iIFKVLnOMQkdKyY8cOGhsb2bp1a9qlCNCzZ09qa2upqKiItbyCQ0T2ucbGRvr160ddXR1mlnY5XZq7s3HjRhobGxkxYkSsPjpUJSL73NatW6msrFRolAAzo7Kysqi9PwWHiKRCoVE6iv1eKDhERKQoCo58vvUtOOustKsQkQ62ceNGxo0bx7hx4xg8eDA1NTUt09u3b8/bd9myZVx77bUFtzFx4sQOqfVXv/oVZ599doesq6Po5Hg+b74Jzz2XdhUi0sEqKyt5+eWXAbj55pvp27cv1113XUv7zp07KS9v/89jQ0MDDQ0NBbfx/PPPd0itpUh7HPmUl8POnWlXISL7wKxZs/jc5z7H5MmTmTt3Li+88AITJ07k6KOPZuLEibzxxhtA6z2Am2++mcsuu4xJkyYxcuRI5s2b17K+vn37tiw/adIkLrjgAkaNGsWMGTPI3Hl10aJFjBo1ihNPPJFrr722qD2Lhx9+mCOPPJIxY8Ywd+5cAJqampg1axZjxozhyCOP5Jvf/CYA8+bNY/To0YwdO5bp06fv9WulPY58ysuhqSntKkQ6v0mTdp130UXw6U/Dli1w5pm7ts+aFR4bNsAFF7Ru+9Wv9qiMP/3pTzzzzDOUlZXx3nvvsWTJEsrLy3nmmWe48cYbefTRR3fp8/rrr/PLX/6S999/n8MPP5wrr7xyl/dD/P73v2fFihUcfPDBnHDCCTz33HM0NDRwxRVXsGTJEkaMGMHFF18cu841a9Ywd+5cXnrpJQYOHMhpp53G448/ztChQ/n73//Oq6++CsC7774LwG233cabb75Jjx49WubtDe1x5KM9DpEu5cILL6SsrAyATZs2ceGFFzJmzBjmzJnDihUr2u1z1lln0aNHD6qqqhg0aBDr1q3bZZkJEyZQW1tLt27dGDduHKtXr+b1119n5MiRLe+dKCY4XnzxRSZNmkR1dTXl5eXMmDGDJUuWMHLkSFatWsU111zDk08+Sf/+/QEYO3YsM2bM4KGHHtrtIbhiaI8jn6FD4eijwR106aBIcvLtIfTunb+9qmqP9zDa6tOnT8vzm266icmTJ/PYY4+xevVqJrW3VwT06NGj5XlZWRk72/lns71lMoer9sTu+g4cOJDly5fz1FNPceedd7JgwQLmz5/Pz3/+c5YsWcLChQu55ZZbWLFixV4FiPY48pk9G154QaEh0gVt2rSJmpoaAO6///4OX/+oUaNYtWoVq1evBuDHP/5x7L7HHnssv/71r9mwYQNNTU08/PDDnHzyyWzYsIHm5mbOP/98brnlFn73u9/R3NzMW2+9xeTJk7n99tt599132bx5817Vrj0OEZF2fOELX2DmzJnccccdTJkypcPX36tXL+666y6mTp1KVVUVEyZM2O2yixcvpra2tmX6Jz/5CbfeeiuTJ0/G3TnzzDOZNm0ay5cv59JLL6W5uRmAW2+9laamJi655BI2bdqEuzNnzhwGDBiwV7Xb3uwu7S8aGhp8j27k9B//Ad/4RrgkN2cXVkT2zmuvvcaHPvShtMtI3ebNm+nbty/uzlVXXUV9fT1z5sxJpZb2vidm9pK773LtsQ5V5bNxIyxfDjt2pF2JiHRC9913H+PGjeOII45g06ZNXHHFFWmXFIsOVeWTOXmkK6tEJAFz5sxJbQ9jb2iPIx8Fh0hiusJh8v1Fsd8LBUc+Cg6RRPTs2ZONGzcqPEpA5n4cPXv2jN1Hh6ryqamBKVOyASIiHaK2tpbGxkbWr1+fdilC9g6AcekvYj5nnBEeItKhKioqYt9tTkqPDlWJiEhREg0OM5tqZm+Y2Uozu76ddjOzeVH7K2Z2TE7bfDN7x8xebdPnQDN72sz+HH0dmNgAnnwSDjkEok/FFBGRBIPDzMqAO4EzgNHAxWY2us1iZwD10eNy4O6ctvuBqe2s+npgsbvXA4uj6WRs3QqrVsEHHyS2CRGR/U2SexwTgJXuvsrdtwOPANPaLDMNeNCDpcAAMxsC4O5LgP9qZ73TgAei5w8A5yZRPKCrqkRE2pFkcNQAb+VMN0bzil2mrYPcfS1A9HVQewuZ2eVmtszMlu3xlRsKDhGRXSQZHO19pGzbi7bjLLNH3P1ed29w94bq6uo9W4mCQ0RkF0kGRyMwNGe6FlizB8u0tS5zOCv6+s5e1rl7gwbBOefAXn6SpIhIZ5JkcLwI1JvZCDPrDkwHFrZZZiHwiejqquOATZnDUHksBGZGz2cCP+vIolsZOxZ+9jMYMyaxTYiI7G8SCw533wlcDTwFvAYscPcVZjbbzGZHiy0CVgErgfuAT2f6m9nDwG+Aw82s0cw+GTXdBpxqZn8GTo2mRURkH9H9OPJ5+WU4/fRwX47TTuvwukRESpnux7En3OGdd/Q+DhGRHAqOfDJXVelGTiIiLRQc+VRUhK+6HFdEpIWCIx+9j0NEZBcKjnz694cZM2D48LQrEREpGbofRz6DBsFDD6VdhYhISdEeh4iIFEXBkc+GDdC7N9x9d+FlRUS6CAVHPmVl4T0c27enXYmISMlQcOSjq6pERHah4MhHwSEisgsFRz4KDhGRXSg48ikvhyuugKOPTrsSEZGSofdx5GMG99yTdhUiIiVFexyFNDdDU1PaVYiIlAwFRyH9+sHcuWlXISJSMhQchZSX6+S4iEgOBUchCg4RkVYUHIWUl+sch4hIDgVHIdrjEBFpRZfjFvLpT8Nhh6VdhYhIyVBwFPLFL6ZdgYhISdGhqkLefx82b067ChGRkqHgKOT442HWrLSrEBEpGQqOQnRyXESkFQVHIQoOEZFWFByFKDhERFpJNDjMbKqZvWFmK83s+nbazczmRe2vmNkxhfqa2TgzW2pmL5vZMjObkOQYFBwiIq0ldjmumZUBdwKnAo3Ai2a20N3/mLPYGUB99DgWuBs4tkDf24EvufsTZnZmND0pqXHwqU+Fe4+LiAiQ7Ps4JgAr3X0VgJk9AkwDcoNjGvCguzuw1MwGmNkQoC5PXwf6R/0PANYkOAZdUSUi0kaSwVEDvJUz3UjYqyi0TE2Bvp8FnjKzrxMOtU1sb+NmdjlwOcCwYcP2aAAAbNgQDlUNHrzn6xAR6USSPMdh7czzmMvk63slMMfdhwJzgO+3t3F3v9fdG9y9obq6OmbJ7Zg1Cz7ykT3vLyLSySQZHI3A0JzpWnY9rLS7ZfL1nQn8NHr+E8IhseTo5LiISCtJBseLQL2ZjTCz7sB0YGGbZRYCn4iurjoO2OTuawv0XQOcHD2fAvw5wTEoOERE2kjsHIe77zSzq4GngDJgvruvMLPZUfs9wCLgTGAlsAW4NF/faNX/A/i2mZUDW4nOYySmvBx27Eh0EyIi+5NEPx3X3RcRwiF33j05zx24Km7faP6zwPiOrTQP7XGIiLSij1Uv5JJL4JRT0q5CRKRkKDgKmTo17QpEREqKPquqkLffhtdfT7sKEZGSoeAo5JZb4MMfTrsKEZGSoeAoRCfHRURaUXAUouAQEWlFwVGIgkNEpBUFRyEKDhGRVnQ5biHnnQeHHpp2FSIiJUPBUUhDQ3iIiAigQ1WFrV0LS5dCU1PalYiIlAQFRyEPPQTHHw9bt6ZdiYhISVBwFFIeHc3TCXIREUDBUZiCQ0SkFQVHIQoOEZFWFByFKDhERFpRcBRyyimwYAEMHJh2JSIiJUHv4yhk5MjwEBERQHscha1bB08/DZs3p12JiEhJUHAUsmQJnHYarF6ddiUiIiVBwVGITo6LiLSi4ChEwSEi0oqCo5BMcOizqkREAAVHYdrjEBFpRcFRyNFHwxNPwOjRaVciIlIS9D6OQqqqYOrUtKsQESkZ2uMo5B//gMceg7ffTrsSEZGSkGhwmNlUM3vDzFaa2fXttJuZzYvaXzGzY+L0NbNrorYVZnZ7kmPgL3+Bj34Uli1LdDMiIvuLxA5VmVkZcCdwKtAIvGhmC939jzmLnQHUR49jgbuBY/P1NbPJwDRgrLtvM7NBSY0B0MlxEZE2ktzjmACsdPdV7r4deITwBz/XNOBBD5YCA8xsSIG+VwK3ufs2AHd/J8ExKDhERNqIFRxm1sfMukXPDzOzc8ysokC3GuCtnOnGaF6cZfL1PQz4sJn91sx+bWb/bTc1X25my8xs2fr16wuUmoeCQ0Sklbh7HEuAnmZWAywGLgXuL9DH2pnnMZfJ17ccGAgcB3weWGBmuyzv7ve6e4O7N1RXVxcoNQ8Fh4hIK3GDw9x9C/BR4H+7+3lAoTc2NAJDc6ZrgTUxl8nXtxH4aXR46wWgGaiKOY7i1dTAs8/C6acntgkRkf1J7OAws+OBGcDPo3mFTqy/CNSb2Qgz6w5MBxa2WWYh8Ino6qrjgE3uvrZA38eBKVFRhwHdgQ0xx1G8Xr3ghBNgb/ZaREQ6kbhXVX0WuAF4zN1XmNlI4Jf5Orj7TjO7GngKKAPmR31nR+33AIuAM4GVwBbCIbDd9o1WPR+Yb2avAtuBme7e9hBYx/ngA/jJT2DCBBg1KrHNiIjsL6zYv7nRSfK+7v5eMiV1vIaGBl+2p+/DWL8eBg2C73wHrrqqYwsTESlhZvaSuze0nR/3qqofmVl/M+sD/BF4w8w+39FFliSdHBcRaSXuOY7R0R7GuYTDS8OAjydVVEnJBMeOHenWISJSIuIGR0X0vo1zgZ+5+w52vbS2c9Ieh4hIK3GD47vAaqAPsMTMhgP7zTmOvVIRvc9RwSEiAsS8qsrd5wHzcmb9NfrMqM6vrAyWL4fBg9OuRESkJMQKDjM7APhX4KRo1q+BLwObEqqrdJjB2LFpVyEiUjLiHqqaD7wPXBQ93gN+kFRRJee734Xnnku7ChGRkhA3OA5x93+NPq12lbt/CRiZZGEl5XOfg8cfT7sKEZGSEDc4PjCzEzMTZnYC8EEyJZWg8nKdHBcRicT9yJHZwIPRuQ6AfwAzkympBCk4RERaxL2qajlwlJn1j6bfM7PPAq8kWFvpUHCIiLQo6g6A7v5ezmdUfS6BekqTgkNEpMXe3HO8vZstdU7PPw99+qRdhYhISdib4OgaHzkCMHx42hWIiJSMvMFhZu/TfkAY0CuRikrRffdBVRWcd17alYiIpC5vcLh7v31VSEn71rdg9GgFh4gIRZ4c77J0clxEpIWCIw4Fh4hICwVHHAoOEZEWCo44FBwiIi325nLcruPnP4duylgREVBwxDNgQNoViIiUDP0bHccDD8Bdd6VdhYhISVBwxLFgAcyfn3YVIiIlQcERh06Oi4i0UHDEoeAQEWmh4IhDwSEi0iLR4DCzqWb2hpmtNLPr22k3M5sXtb9iZscU0fc6M3Mzq0pyDEAIjqamxDcjIrI/SOxyXDMrA+4ETgUagRfNbKG7/zFnsTOA+uhxLHA3cGyhvmY2NGr7W1L1t/KDH4B1nduPiIjkk+QexwRgpbuvcvftwCPAtDbLTAMe9GApMMDMhsTo+03gC+yre4J07w4VFftkUyIipS7J4KgB3sqZbozmxVlmt33N7Bzg79F90HfLzC43s2Vmtmz9+vV7NoKMBQvgxhv3bh0iIp1EksHR3rGdtnsIu1um3flm1hv4IvC/Cm3c3e919wZ3b6iuri5YbF5LloSbOYmISKLB0QgMzZmuBdbEXGZ38w8BRgDLzWx1NP93Zja4QytvS1dViYi0SDI4XgTqzWyEmXUHpgML2yyzEPhEdHXVccAmd1+7u77u/gd3H+Tude5eRwiYY9z97QTHoeAQEcmR2FVV7r7TzK4GngLKgPnuvsLMZkft9wCLgDOBlcAW4NJ8fZOqtSAFh4hIi0Q/HdfdFxHCIXfePTnPHbgqbt92lqnb+ypj6N5dH6suIhLRX8M4vvxl+Oc/065CRKQkKDhERKQoCo44Fi2CWbNg+/a0KxERSZ2CI44VK8LNnHbsSLsSEZHUKTjiKI+uIdCVVSIiCo5YFBwiIi0UHHEoOEREWig44ujdGyorobk57UpERFKn4Ihj5kzYsAGGDEm7EhGR1Ck4RESkKAqOOJ57Ds4/Hxob065ERCR1Co441qyBn/4UNm1KuxIRkdQpOOLQVVUiIi0UHHEoOEREWig44lBwiIi0UHDE0bcv1NVlA0REpAvTX8I4PvxhePPNtKsQESkJ2uMQEZGiKDjieO01OO00eOGFtCsREUmdgiOOzZvh6adh/fq0KxERSZ2CIw5dVSUi0kLBEYeCQ0SkhYIjDgWHiEgLBUccvXvDmDHh/RwiIl2c3scRx/Dh8Ic/pF2FiEhJ0B6HiIgURcERx8aNcPzx8OijaVciIpK6RIPDzKaa2RtmttLMrm+n3cxsXtT+ipkdU6ivmf27mb0eLf+YmQ1IcgxAuNf40qWwdm3imxIRKXWJBYeZlQF3AmcAo4GLzWx0m8XOAOqjx+XA3TH6Pg2McfexwJ+AG5IaQwtdVSUi0iLJPY4JwEp3X+Xu24FHgGltlpkGPOjBUmCAmQ3J19fdf+Humb/gS4HaBMcQKDhERFokGRw1wFs5043RvDjLxOkLcBnwRHsbN7PLzWyZmS1bv7cfFaLgEBFpkWRwWDvzPOYyBfua2ReBncAP29u4u9/r7g3u3lBdXR2j3DwqKsLJ8YMP3rv1iIh0Akm+j6MRGJozXQusiblM93x9zWwmcDZwiru3DaOOV14Ozz+f+GZERPYHSe5xvAjUm9kIM+sOTAcWtllmIfCJ6Oqq44BN7r42X18zmwrMBc5x9y0J1i8iIu1ILDiiE9hXA08BrwEL3H2Fmc02s9nRYouAVcBK4D7g0/n6Rn2+A/QDnjazl83snqTG0Mr48XDHHftkUyIipSzRjxxx90WEcMidd0/Ocweuits3mn9oB5cZz+uv630cIiLonePxlZfrqioRERQc8Sk4REQABUd85eWwY0faVYiIpE7BEdeUKTBqVNpViIikTvfjiOvhh9OuQESkJGiPQ0REiqLgiGvKFLiq3SuHRUS6FB2qimvdOqisTLsKEZHUaY8jLl2OKyICKDjiU3CIiAAKjvgUHCIigM5xxHfKKdC7d9pViIikTsER17/9W9oViIiUBB2qEhGRoig44rrwQjj11LSrEBFJnYIjri1b4N13065CRCR1Co64dFWViAig4IhPwSEiAig44lNwiIgAuhw3vsmTYeTItKsQEUmdgiOu2bPTrkBEpCToUJWIiBRFwRHXVVdBTU3aVYiIpE7BUYzt29OuQEQkdQqOuHRVlYgIoOCIT8EhIgIoOOJTcIiIAAlfjmtmU4FvA2XA99z9tjbtFrWfCWwBZrn77/L1NbMDgR8DdcBq4CJ3/0eS4wDgxBNhx47w/Lrr4P33oVs3KCsLX8ePh5kzQ/tll4XzIWVl0L8/DBwIEyfC1KnQ3Azf+15Y17Zt4dGrFxx3XHjs3AlLl4Z5FRVhHeXlUF0NBx4ITU3h/uc7doRtuIflqqqgX7+w/qam0Ke5ufV0Jvy2bAn9Mo/mZujbF3r0CO3btoUxZR6ZMeZyD+t1D9OZZZqastPtaWrKLlNevut6MzU3N4fpigowi/992rYt9M28bm3X33YMUNz6m5vzr7MQ9/Aa79wZxlauK+JlP+TuiTwIf/D/AowEugPLgdFtljkTeAIw4Djgt4X6ArcD10fPrwe+VqiW8ePHe4caO9b9oIPcq6vdDzzQfcAA99mzs+1HHOE+cqT78OGhzcz9mmtC27ZtuX+ys48bbwztGza03/7Vr4b2Vavab583L7S/8kr77fffH9qffbb99kcfDe1PPNF++1NPhfYFC9pv/81vQvv3vx+mKyrcDzjAfeBA91693F97LbR/85ut+5m5l5e7/+1vof3LX961vU8f940bQ/uNN7r36OHes2eY369feN7UFNpnz27dv7zcvbIy+7255hr3QYNCv7KysMyQIdn2iy4KbQcc4N6/f3g+bly2/eSTQ7/evcPYKivdp0zJtp9+uvvgwdnHQQe5n3NOtv3QQ1vX1727+wUXZNvr68N2+/fPvn6XX55tHznSvaoqbHfQoLCNuXNDW3Nz+JnMPCorQ/033BDaN28O68y0Z9Zz++2hfc2a7Jhy2++8M7SvXOleU+M+dGj42R4xInz90Y9C+8svh/EOGRLqymx/wYLQvmRJ+H056KCwjkz/xYtD+5NPZn+vMtuurHR/7rnQ/thj7sOG7fr4wx9C+/33h+0OGZKtc9iw8Dvj7n7XXaEts/7Bg91ra93XrQvtt90W2jJjqKkJX//5z9D+L/+SrevAA8NrNXBgeN3d3W+6KXz/DjkkO7YxY1r/7B1ySFjmsMPcDz/c/aSTsu0f/3ioZ9gw97q68L0+/fRs+7nnhnoyywwf7n7WWdn2KVNCzSNHhm0cfrj717/uewNY5u38TU3y350JwEp3XwVgZo8A04A/5iwzDXgwKnCpmQ0wsyGEvYnd9Z0GTIr6PwD8Cpib4Dh2tXx5/vZXX2093dyc3VupqIDGxvC1Z0/o3h0++CD7X2y/fvCLX4R5O3aE/8537oSjjgrtBx4I99wT+mX+G9+xA449NrRXV8NXvpLd48nsCRxzTGivq4NvfCM8N8vuVWTWf9hh8LWvZfdEMnsshx4a2kePhptuyq7XLDxqa0P7+PHwpS+F+rdsCf179YIDDgjtEyfCV7+a3WPZuTN87dcvtE+aBLfcEtbtDlu3hnX16ZPtv3Nntn9zc3gtMnsC550Hw4dn1932SrgxY8K83r3Do6ys9Z0dTzsNDj44uz6zsDeX8clPhr3PrVvD3o1768u0TzopbD/XqFHZ55/5TPiU5fLy8H3bsiX72gJMnx72ZjN7Q01N4TXNOPvs0M8s+70ZPTr7/Tz//Oz3xCy8Nscfn22fOTP7mmSWOeKIMN2rF8yYkX1tMz8fhx8e2nv3htNPD9vN/HyYwZAhof2AA+Dcc7N7i927h8dhh4Xpgw6Ciy8O9Wce3bqFn2mAwYND/9z6AQYNyn6dMoVdZH52hg+Hj3wkPM+8Npm6AUaMgLPOCr83mde2qSn8HkJ4Hc8/v/XPVu7e9lFHwUUXtX7tysqydQ4ZEr5XmXndurX+2aqvD7+nmdfPHSors+3jx4faMrW7Z19bCN/HqqrW7fX12fZJk8Lvd2avu7m5df8OZJ75Ae3oFZtdAEx1909F0x8HjnX3q3OW+T/Abe7+bDS9mBACdbvra2bvuvuAnHX8w90HtrP9y4HLAYYNGzb+r3/9ayLjFBHprMzsJXdvaDs/yZPj7R04bptSu1smTt+83P1ed29w94bq6upiuoqISB5JBkcjMDRnuhZYE3OZfH3XRYeziL6+04E1i4hIAUkGx4tAvZmNMLPuwHRgYZtlFgKfsOA4YJO7ry3QdyEQXb7ETOBnCY5BRETaSOzkuLvvNLOrgacIV0nNd/cVZjY7ar8HWES4smol4XLcS/P1jVZ9G7DAzD4J/A24MKkxiIjIrhI7OV5KGhoafNmyZWmXISKyX0nj5LiIiHRCCg4RESmKgkNERIrSJc5xmNl6oJh3AFYBGxIqp5R1xXF3xTFD1xx3Vxwz7N24h7v7Lm+E6xLBUSwzW9beCaHOriuOuyuOGbrmuLvimCGZcetQlYiIFEXBISIiRVFwtO/etAtISVccd1ccM3TNcXfFMUMC49Y5DhERKYr2OEREpCgKDhERKYqCow0zm2pmb5jZSjO7Pu16kmBmQ83sl2b2mpmtMLPPRPMPNLOnzezP0dddbpC1vzOzMjP7fXQTsa4y5gFm9p9m9nr0PT++s4/bzOZEP9uvmtnDZtazM47ZzOab2Ttm9mrOvN2O08xuiP62vWFmp+/pdhUcOcysDLgTOAMYDVxsZqPTrSoRO4H/6e4fItzr/aponNcDi929HlgcTXc2nwFey5nuCmP+NvCku48CjiKMv9OO28xqgGuBBncfQ/iE7el0zjHfD0xtM6/dcUa/49OBI6I+d0V/84qm4Git5T7p7r4dyNzrvFNx97Xu/rvo+fuEPyQ1hLE+EC32AHBuKgUmxMxqgbOA7+XM7uxj7g+cBHwfwN23u/u7dPJxE24Z0cvMyoHehBvBdboxu/sS4L/azN7dOKcBj7j7Nnd/k3A7iwl7sl0FR2s1wFs5043RvE7LzOqAo4HfAgdFN9Ii+jooxdKS8C3gC0BzzrzOPuaRwHrgB9Ehuu+ZWR868bjd/e/A1wn361lLuEHcL+jEY25jd+PssL9vCo7W9vpe5/sTM+sLPAp81t3fS7ueJJnZ2cA77v5S2rXsY+XAMcDd7n408E86xyGa3YqO6U8DRgAHA33M7JJ0qyoJHfb3TcHRWpz7pHcKZlZBCI0fuvtPo9md+X7uJwDnmNlqwiHIKWb2EJ17zBB+phvd/bfR9H8SgqQzj/u/A2+6+3p33wH8FJhI5x5zrt2Ns8P+vik4Wotzn/T9npkZ4Zj3a+5+R05Tp72fu7vf4O617l5H+L7+X3e/hE48ZgB3fxt4y8wOj2adAvyRzj3uvwHHmVnv6Gf9FMJ5vM485ly7G+dCYLqZ9TCzEUA98MKebEDvHG/DzM4kHAvP3Ov8q+lW1PHM7ETg/wF/IHu8/0bCeY4FwDCi+7m7e9sTb/s9M5sEXOfuZ5tZJZ18zGY2jnBBQHdgFXAp4Z/GTjtuM/sS8DHCFYS/Bz4F9KWTjdnMHgYmET46fR3wr8Dj7GacZvZF4DLC6/JZd39ij7ar4BARkWLoUJWIiBRFwSEiIkVRcIiISFEUHCIiUhQFh4iIFEXBIdIBzKzJzF7OeXTYu7PNrC73009F0laedgEincQH7j4u7SJE9gXtcYgkyMxWm9nXzOyF6HFoNH+4mS02s1eir8Oi+QeZ2WNmtjx6TIxWVWZm90X3mPiFmfVKbVDS5Sk4RDpGrzaHqj6W0/aeu08AvkP4VAKi5w+6+1jgh8C8aP484NfufhThM6VWRPPrgTvd/QjgXeD8REcjkofeOS7SAcxss7v3bWf+amCKu6+KPljybXevNLMNwBB33xHNX+vuVWa2Hqh1920566gDno5uzIOZzQUq3P0r+2BoIrvQHodI8nw3z3e3THu25TxvQucnJUUKDpHkfSzn62+i588TPqUXYAbwbPR8MXAltNwfvf++KlIkLv3XItIxepnZyznTT7p75pLcHmb2W8I/ahdH864F5pvZ5wl36Ls0mv8Z4F4z+yRhz+JKwl3sREqGznGIJCg6x9Hg7hvSrkWko+hQlYiIFEV7HCIiUhTtcYiISFEUHCIiUhQFh4iIFEXBISIiRVFwiIhIUf4/PeuPaAWYU5QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cnn-lstm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import array\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=32, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_x, train_y, verbose=1, batch_size=16, epochs=100)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20051047776801362"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scaled_data[training_data_len - 5: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(5, len(test_data)):\n",
    "    x_test.append(test_data[i-5:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], n_steps, 1, n_length, n_features ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions3 = model.predict(x_test)\n",
    "predictions3_3 = np.reshape(predictions3,(predictions3.shape[0],1))\n",
    "predictions34 = scaler.inverse_transform(predictions3_3)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions34 - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-59fc5f4e9ffd>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_c['Predictions3'] = predictions34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08806611519609994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "train = data[:training_data_len]\n",
    "valid_c = data[training_data_len:]\n",
    "valid_c['Predictions3'] = predictions34\n",
    "\n",
    "mape(valid_c['Close'], valid_c['Predictions3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 3, 32)          12800     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 96)                0         \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 96)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 200)            237600    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 100)           20100     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 270,601\n",
      "Trainable params: 270,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
