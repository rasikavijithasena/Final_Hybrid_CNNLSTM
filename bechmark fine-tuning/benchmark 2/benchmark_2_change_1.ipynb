{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load local .csv file as DataFrame\n",
    "df = pd.read_csv('aapl_all_csv.csv')\n",
    "# Inspect the data\n",
    "df = df[:12000]\n",
    "\n",
    "df['Date'] = df['Datetime'].str[:-6]\n",
    "df['Date']=pd.to_datetime(df[\"Date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "data_date = df.filter(['Date'])\n",
    "\n",
    "data_date = data_date.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_date = int(np.ceil( len(data_date) * .95 ))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler1 = MinMaxScaler(feature_range=(0,1))\n",
    "#scaled_data1 = scaler1.fit_transform(data_date)\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data_date = data_date[0:int(training_data_date), :]\n",
    "\n",
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585])]\n",
      "[0.8192645319337108]\n",
      "\n",
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585]), array([0.81144125, 0.81464378, 0.81855352, 0.81982585, 0.81926453])]\n",
      "[0.8192645319337108, 0.8167762641645444]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(5, len(train_data)):\n",
    "    x_train.append(train_data[i-5:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 6:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "#x_train = np.reshape(x_train, ( x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 1\n",
    "n_length = 5\n",
    "n_features = 1\n",
    "n_outputs=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11395, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_train.reshape((x_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "# reshape output into [samples, timesteps, features]\n",
    "train_y = y_train.reshape((y_train.shape[0],1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "713/713 [==============================] - 13s 9ms/step - loss: 0.0108\n",
      "Epoch 2/100\n",
      "713/713 [==============================] - 7s 9ms/step - loss: 9.5847e-05\n",
      "Epoch 3/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 9.3662e-05\n",
      "Epoch 4/100\n",
      "713/713 [==============================] - 6s 9ms/step - loss: 9.5118e-05\n",
      "Epoch 5/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 9.1633e-05\n",
      "Epoch 6/100\n",
      "713/713 [==============================] - 7s 9ms/step - loss: 9.2481e-05\n",
      "Epoch 7/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 7.9316e-05\n",
      "Epoch 8/100\n",
      "713/713 [==============================] - 7s 9ms/step - loss: 8.6635e-05\n",
      "Epoch 9/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 7.2682e-05\n",
      "Epoch 10/100\n",
      "713/713 [==============================] - 7s 10ms/step - loss: 7.2801e-05\n",
      "Epoch 11/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 6.4499e-05\n",
      "Epoch 12/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.8510e-05\n",
      "Epoch 13/100\n",
      "713/713 [==============================] - 14s 19ms/step - loss: 6.5996e-05\n",
      "Epoch 14/100\n",
      "713/713 [==============================] - 10s 14ms/step - loss: 7.4408e-05\n",
      "Epoch 15/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 6.6693e-05\n",
      "Epoch 16/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.8541e-05\n",
      "Epoch 17/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 6.6196e-05\n",
      "Epoch 18/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.6961e-05\n",
      "Epoch 19/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.1348e-05\n",
      "Epoch 20/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.6304e-05\n",
      "Epoch 21/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 6.7155e-05\n",
      "Epoch 22/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.0918e-05\n",
      "Epoch 23/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.9234e-05\n",
      "Epoch 24/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 6.3410e-05\n",
      "Epoch 25/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.2540e-05\n",
      "Epoch 26/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.2494e-05\n",
      "Epoch 27/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 6.0426e-05\n",
      "Epoch 28/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.1522e-05\n",
      "Epoch 29/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.9466e-05\n",
      "Epoch 30/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.9396e-05\n",
      "Epoch 31/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.9418e-05\n",
      "Epoch 32/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 6.3505e-05\n",
      "Epoch 33/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 6.3891e-05\n",
      "Epoch 34/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.9193e-05\n",
      "Epoch 35/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.8531e-05\n",
      "Epoch 36/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.6487e-05\n",
      "Epoch 37/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 6.0492e-05\n",
      "Epoch 38/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.7575e-05\n",
      "Epoch 39/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.8342e-05\n",
      "Epoch 40/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.4542e-05\n",
      "Epoch 41/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 6.0665e-05\n",
      "Epoch 42/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.5118e-05\n",
      "Epoch 43/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.7508e-05\n",
      "Epoch 44/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 6.1129e-05\n",
      "Epoch 45/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.7792e-05\n",
      "Epoch 46/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5658e-05\n",
      "Epoch 47/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.7353e-05\n",
      "Epoch 48/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.8488e-05\n",
      "Epoch 49/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.7923e-05\n",
      "Epoch 50/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.7583e-05\n",
      "Epoch 51/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.6861e-05\n",
      "Epoch 52/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5350e-05\n",
      "Epoch 53/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 6.3415e-05\n",
      "Epoch 54/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.3231e-05\n",
      "Epoch 55/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.7597e-05\n",
      "Epoch 56/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.7966e-05\n",
      "Epoch 57/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5581e-05\n",
      "Epoch 58/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.7000e-05\n",
      "Epoch 59/100\n",
      "713/713 [==============================] - 9s 12ms/step - loss: 5.5608e-05\n",
      "Epoch 60/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3643e-05\n",
      "Epoch 61/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.6626e-05\n",
      "Epoch 62/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.4911e-05\n",
      "Epoch 63/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.6443e-05\n",
      "Epoch 64/100\n",
      "713/713 [==============================] - 13s 19ms/step - loss: 5.8752e-05\n",
      "Epoch 65/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.4205e-05\n",
      "Epoch 66/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.4662e-05\n",
      "Epoch 67/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.6472e-05\n",
      "Epoch 68/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.7461e-05\n",
      "Epoch 69/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.5719e-05\n",
      "Epoch 70/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.4046e-05\n",
      "Epoch 71/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.6842e-05\n",
      "Epoch 72/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3927e-05\n",
      "Epoch 73/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.4084e-05\n",
      "Epoch 74/100\n",
      "713/713 [==============================] - 14s 19ms/step - loss: 5.7706e-05\n",
      "Epoch 75/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.4945e-05\n",
      "Epoch 76/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.5531e-05\n",
      "Epoch 77/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.3763e-05\n",
      "Epoch 78/100\n",
      "713/713 [==============================] - 13s 18ms/step - loss: 5.5345e-05\n",
      "Epoch 79/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.3478e-05\n",
      "Epoch 80/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.8204e-05\n",
      "Epoch 81/100\n",
      "713/713 [==============================] - 12s 18ms/step - loss: 5.2511e-05\n",
      "Epoch 82/100\n",
      "713/713 [==============================] - 10s 14ms/step - loss: 5.5270e-05\n",
      "Epoch 83/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.2374e-05\n",
      "Epoch 84/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.2169e-05\n",
      "Epoch 85/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3326e-05\n",
      "Epoch 86/100\n",
      "713/713 [==============================] - 8s 12ms/step - loss: 5.2478e-05\n",
      "Epoch 87/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.6157e-05\n",
      "Epoch 88/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.1761e-05\n",
      "Epoch 89/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.5626e-05\n",
      "Epoch 90/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.3151e-05\n",
      "Epoch 91/100\n",
      "713/713 [==============================] - 12s 17ms/step - loss: 5.4047e-05\n",
      "Epoch 92/100\n",
      "713/713 [==============================] - 9s 13ms/step - loss: 5.4204e-05\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713/713 [==============================] - 12s 16ms/step - loss: 5.5880e-05\n",
      "Epoch 94/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.3526e-05\n",
      "Epoch 95/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.3930e-05\n",
      "Epoch 96/100\n",
      "713/713 [==============================] - 12s 16ms/step - loss: 5.6742e-05\n",
      "Epoch 97/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.5057e-05\n",
      "Epoch 98/100\n",
      "713/713 [==============================] - 8s 11ms/step - loss: 5.1870e-05\n",
      "Epoch 99/100\n",
      "713/713 [==============================] - 11s 16ms/step - loss: 5.2818e-05\n",
      "Epoch 100/100\n",
      "713/713 [==============================] - 11s 15ms/step - loss: 5.2251e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cnn-lstm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import array\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=128, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(RepeatVector(n_outputs))\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_x, train_y, verbose=1, batch_size=16, epochs=100)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.legend(['Training Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23845279236078623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scaled_data[training_data_len - 5: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(5, len(test_data)):\n",
    "    x_test.append(test_data[i-5:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], n_steps, 1, n_length, n_features ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions3 = model.predict(x_test)\n",
    "predictions3_3 = np.reshape(predictions3,(predictions3.shape[0],1))\n",
    "predictions34 = scaler.inverse_transform(predictions3_3)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions34 - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-59fc5f4e9ffd>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_c['Predictions3'] = predictions34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1180542413828074"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "train = data[:training_data_len]\n",
    "valid_c = data[training_data_len:]\n",
    "valid_c['Predictions3'] = predictions34\n",
    "\n",
    "mape(valid_c['Close'], valid_c['Predictions3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm2d (ConvLSTM2D)    (None, 1, 3, 128)         198656    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 384)               0         \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 1, 384)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 200)            468000    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1, 100)           20100     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1, 1)             101       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 686,857\n",
      "Trainable params: 686,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
