{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-31 13:30:00-05:00</td>\n",
       "      <td>177.610001</td>\n",
       "      <td>177.695007</td>\n",
       "      <td>177.570007</td>\n",
       "      <td>177.595001</td>\n",
       "      <td>177.595001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-31 13:31:00-05:00</td>\n",
       "      <td>177.595001</td>\n",
       "      <td>177.619995</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>177.549896</td>\n",
       "      <td>177.549896</td>\n",
       "      <td>94884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-31 13:32:00-05:00</td>\n",
       "      <td>177.550003</td>\n",
       "      <td>177.660004</td>\n",
       "      <td>177.541000</td>\n",
       "      <td>177.639999</td>\n",
       "      <td>177.639999</td>\n",
       "      <td>71624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-31 13:33:00-05:00</td>\n",
       "      <td>177.639999</td>\n",
       "      <td>177.778900</td>\n",
       "      <td>177.630096</td>\n",
       "      <td>177.750000</td>\n",
       "      <td>177.750000</td>\n",
       "      <td>143784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-31 13:34:00-05:00</td>\n",
       "      <td>177.740005</td>\n",
       "      <td>177.910004</td>\n",
       "      <td>177.740005</td>\n",
       "      <td>177.785797</td>\n",
       "      <td>177.785797</td>\n",
       "      <td>276125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime        Open        High         Low       Close  \\\n",
       "0  2021-12-31 13:30:00-05:00  177.610001  177.695007  177.570007  177.595001   \n",
       "1  2021-12-31 13:31:00-05:00  177.595001  177.619995  177.500000  177.549896   \n",
       "2  2021-12-31 13:32:00-05:00  177.550003  177.660004  177.541000  177.639999   \n",
       "3  2021-12-31 13:33:00-05:00  177.639999  177.778900  177.630096  177.750000   \n",
       "4  2021-12-31 13:34:00-05:00  177.740005  177.910004  177.740005  177.785797   \n",
       "\n",
       "    Adj Close  Volume  \n",
       "0  177.595001       0  \n",
       "1  177.549896   94884  \n",
       "2  177.639999   71624  \n",
       "3  177.750000  143784  \n",
       "4  177.785797  276125  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load local .csv file as DataFrame\n",
    "df = pd.read_csv('aapl_all_csv.csv')\n",
    "# Inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Datetime'].str[:-6]\n",
    "df['Date']=pd.to_datetime(df[\"Date\"]).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "data_date = df.filter(['Date'])\n",
    "\n",
    "data_date = data_date.values\n",
    "\n",
    "# Get the number of rows to train the model and validations\n",
    "training_data_date = int(np.ceil( len(data_date) * .95 ))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the scaled training data set\n",
    "train_data_date = data_date[0:int(training_data_date), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the 'Close column \n",
    "data = df.filter(['Close'])\n",
    "# Convert the dataframe to a numpy array\n",
    "dataset = data.values\n",
    "# Get the number of rows to train the model on\n",
    "training_data_len = int(np.ceil( len(dataset) * .95 ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585,\n",
      "       0.81926453, 0.81677626, 0.81428854, 0.81392572, 0.81428854,\n",
      "       0.81215931, 0.81049595, 0.8085945 , 0.80895678, 0.80789053,\n",
      "       0.80639801, 0.80504378, 0.80735741, 0.80824631, 0.80789053,\n",
      "       0.80717953, 0.80966399, 0.80771319, 0.80824957, 0.80931256,\n",
      "       0.81073403, 0.81073403, 0.81108927, 0.8103788 , 0.81144505,\n",
      "       0.81091192, 0.81304441, 0.81375542, 0.8123334 , 0.8132223 ,\n",
      "       0.81251129, 0.81499901, 0.81215605, 0.81002302, 0.81073403,\n",
      "       0.81208826, 0.8103788 , 0.81128831, 0.8103788 , 0.8132223 ,\n",
      "       0.81251129, 0.81073403, 0.81002302, 0.80966779, 0.80966779,\n",
      "       0.80967159, 0.80860154, 0.80745015, 0.80522492, 0.80362556,\n",
      "       0.80433657, 0.80504703, 0.80504703, 0.80575805, 0.80611328])]\n",
      "[0.8091346667936978]\n",
      "\n",
      "[array([0.81304441, 0.81144125, 0.81464378, 0.81855352, 0.81982585,\n",
      "       0.81926453, 0.81677626, 0.81428854, 0.81392572, 0.81428854,\n",
      "       0.81215931, 0.81049595, 0.8085945 , 0.80895678, 0.80789053,\n",
      "       0.80639801, 0.80504378, 0.80735741, 0.80824631, 0.80789053,\n",
      "       0.80717953, 0.80966399, 0.80771319, 0.80824957, 0.80931256,\n",
      "       0.81073403, 0.81073403, 0.81108927, 0.8103788 , 0.81144505,\n",
      "       0.81091192, 0.81304441, 0.81375542, 0.8123334 , 0.8132223 ,\n",
      "       0.81251129, 0.81499901, 0.81215605, 0.81002302, 0.81073403,\n",
      "       0.81208826, 0.8103788 , 0.81128831, 0.8103788 , 0.8132223 ,\n",
      "       0.81251129, 0.81073403, 0.81002302, 0.80966779, 0.80966779,\n",
      "       0.80967159, 0.80860154, 0.80745015, 0.80522492, 0.80362556,\n",
      "       0.80433657, 0.80504703, 0.80504703, 0.80575805, 0.80611328]), array([0.81144125, 0.81464378, 0.81855352, 0.81982585, 0.81926453,\n",
      "       0.81677626, 0.81428854, 0.81392572, 0.81428854, 0.81215931,\n",
      "       0.81049595, 0.8085945 , 0.80895678, 0.80789053, 0.80639801,\n",
      "       0.80504378, 0.80735741, 0.80824631, 0.80789053, 0.80717953,\n",
      "       0.80966399, 0.80771319, 0.80824957, 0.80931256, 0.81073403,\n",
      "       0.81073403, 0.81108927, 0.8103788 , 0.81144505, 0.81091192,\n",
      "       0.81304441, 0.81375542, 0.8123334 , 0.8132223 , 0.81251129,\n",
      "       0.81499901, 0.81215605, 0.81002302, 0.81073403, 0.81208826,\n",
      "       0.8103788 , 0.81128831, 0.8103788 , 0.8132223 , 0.81251129,\n",
      "       0.81073403, 0.81002302, 0.80966779, 0.80966779, 0.80967159,\n",
      "       0.80860154, 0.80745015, 0.80522492, 0.80362556, 0.80433657,\n",
      "       0.80504703, 0.80504703, 0.80575805, 0.80611328, 0.80913467])]\n",
      "[0.8091346667936978, 0.8102009118928386]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# Create the training data set \n",
    "# Create the scaled training data set\n",
    "train_data = scaled_data[0:int(training_data_len), :]\n",
    "# Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60, len(train_data)):\n",
    "    x_train.append(train_data[i-60:i, 0])\n",
    "    y_train.append(train_data[i, 0])\n",
    "    if i<= 61:\n",
    "        print(x_train)\n",
    "        print(y_train)\n",
    "        print()\n",
    "        \n",
    "# Convert the x_train and y_train to numpy arrays \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Reshape the data\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "792/792 [==============================] - 76s 92ms/step - loss: 0.0030\n",
      "Epoch 2/100\n",
      "792/792 [==============================] - 59s 74ms/step - loss: 5.9882e-04\n",
      "Epoch 3/100\n",
      "792/792 [==============================] - 56s 71ms/step - loss: 4.4794e-04\n",
      "Epoch 4/100\n",
      "792/792 [==============================] - 53s 67ms/step - loss: 3.0932e-04\n",
      "Epoch 5/100\n",
      "792/792 [==============================] - 84s 106ms/step - loss: 2.3248e-04\n",
      "Epoch 6/100\n",
      "792/792 [==============================] - 94s 119ms/step - loss: 1.8625e-04\n",
      "Epoch 7/100\n",
      "792/792 [==============================] - 88s 111ms/step - loss: 1.7767e-04\n",
      "Epoch 8/100\n",
      "792/792 [==============================] - 65s 81ms/step - loss: 1.4720e-04\n",
      "Epoch 9/100\n",
      "792/792 [==============================] - 67s 84ms/step - loss: 1.6200e-04\n",
      "Epoch 10/100\n",
      "792/792 [==============================] - 122s 154ms/step - loss: 1.5045e-04\n",
      "Epoch 11/100\n",
      "792/792 [==============================] - 103s 130ms/step - loss: 1.4683e-04\n",
      "Epoch 12/100\n",
      "792/792 [==============================] - 98s 124ms/step - loss: 1.7246e-04\n",
      "Epoch 13/100\n",
      "792/792 [==============================] - 77s 98ms/step - loss: 1.4943e-04\n",
      "Epoch 14/100\n",
      "792/792 [==============================] - 54s 68ms/step - loss: 1.3933e-04\n",
      "Epoch 15/100\n",
      "792/792 [==============================] - 48s 60ms/step - loss: 1.5855e-04\n",
      "Epoch 16/100\n",
      "792/792 [==============================] - 48s 60ms/step - loss: 1.3627e-04\n",
      "Epoch 17/100\n",
      "792/792 [==============================] - 47s 59ms/step - loss: 1.2296e-04\n",
      "Epoch 18/100\n",
      "792/792 [==============================] - 47s 60ms/step - loss: 1.3406e-04\n",
      "Epoch 19/100\n",
      "792/792 [==============================] - 48s 60ms/step - loss: 1.5092e-04\n",
      "Epoch 20/100\n",
      "792/792 [==============================] - 53s 67ms/step - loss: 1.2486e-04\n",
      "Epoch 21/100\n",
      "792/792 [==============================] - 54s 68ms/step - loss: 1.3398e-04\n",
      "Epoch 22/100\n",
      "792/792 [==============================] - 48s 61ms/step - loss: 1.1878e-04\n",
      "Epoch 23/100\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 1.1947e-04\n",
      "Epoch 24/100\n",
      "792/792 [==============================] - 49s 62ms/step - loss: 1.2282e-04\n",
      "Epoch 25/100\n",
      "792/792 [==============================] - 49s 62ms/step - loss: 1.2015e-04\n",
      "Epoch 26/100\n",
      "792/792 [==============================] - 48s 61ms/step - loss: 1.1840e-04\n",
      "Epoch 27/100\n",
      "792/792 [==============================] - 50s 63ms/step - loss: 1.1613e-04\n",
      "Epoch 28/100\n",
      "792/792 [==============================] - 49s 62ms/step - loss: 1.2509e-04\n",
      "Epoch 29/100\n",
      "792/792 [==============================] - 50s 63ms/step - loss: 1.2549e-04\n",
      "Epoch 30/100\n",
      "792/792 [==============================] - 55s 69ms/step - loss: 1.1034e-04\n",
      "Epoch 31/100\n",
      "792/792 [==============================] - 54s 68ms/step - loss: 1.2282e-04\n",
      "Epoch 32/100\n",
      "792/792 [==============================] - 50s 63ms/step - loss: 1.1489e-04\n",
      "Epoch 33/100\n",
      "792/792 [==============================] - 49s 62ms/step - loss: 1.1624e-04\n",
      "Epoch 34/100\n",
      "792/792 [==============================] - 45s 57ms/step - loss: 1.1744e-04\n",
      "Epoch 35/100\n",
      "792/792 [==============================] - 44s 55ms/step - loss: 1.1721e-04\n",
      "Epoch 36/100\n",
      "792/792 [==============================] - 48s 60ms/step - loss: 1.1350e-04\n",
      "Epoch 37/100\n",
      "792/792 [==============================] - 46s 58ms/step - loss: 1.1711e-04\n",
      "Epoch 38/100\n",
      "792/792 [==============================] - 48s 61ms/step - loss: 1.1312e-04\n",
      "Epoch 39/100\n",
      "792/792 [==============================] - 40s 51ms/step - loss: 1.1763e-04\n",
      "Epoch 40/100\n",
      "792/792 [==============================] - 46s 59ms/step - loss: 1.1386e-04\n",
      "Epoch 41/100\n",
      "792/792 [==============================] - 49s 62ms/step - loss: 1.1153e-04\n",
      "Epoch 42/100\n",
      "792/792 [==============================] - 60s 76ms/step - loss: 1.0716e-04\n",
      "Epoch 43/100\n",
      "792/792 [==============================] - 54s 68ms/step - loss: 1.0597e-04\n",
      "Epoch 44/100\n",
      "792/792 [==============================] - 58s 73ms/step - loss: 1.0853e-04\n",
      "Epoch 45/100\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 1.1495e-04\n",
      "Epoch 46/100\n",
      "792/792 [==============================] - 47s 60ms/step - loss: 1.1133e-04\n",
      "Epoch 47/100\n",
      "792/792 [==============================] - 49s 63ms/step - loss: 1.1083e-04\n",
      "Epoch 48/100\n",
      "792/792 [==============================] - 48s 61ms/step - loss: 1.0572e-04\n",
      "Epoch 49/100\n",
      "792/792 [==============================] - 44s 56ms/step - loss: 1.1393e-04\n",
      "Epoch 50/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 1.0710e-04\n",
      "Epoch 51/100\n",
      "792/792 [==============================] - 38s 47ms/step - loss: 1.0493e-04\n",
      "Epoch 52/100\n",
      "792/792 [==============================] - 45s 57ms/step - loss: 1.1144e-04\n",
      "Epoch 53/100\n",
      "792/792 [==============================] - 46s 58ms/step - loss: 1.0997e-04\n",
      "Epoch 54/100\n",
      "792/792 [==============================] - 44s 56ms/step - loss: 9.8398e-05\n",
      "Epoch 55/100\n",
      "792/792 [==============================] - 42s 53ms/step - loss: 1.0410e-04\n",
      "Epoch 56/100\n",
      "792/792 [==============================] - 47s 59ms/step - loss: 1.1088e-04\n",
      "Epoch 57/100\n",
      "792/792 [==============================] - 47s 60ms/step - loss: 9.9703e-05\n",
      "Epoch 58/100\n",
      "792/792 [==============================] - 48s 61ms/step - loss: 1.0096e-04\n",
      "Epoch 59/100\n",
      "792/792 [==============================] - 44s 55ms/step - loss: 1.0519e-04\n",
      "Epoch 60/100\n",
      "792/792 [==============================] - 41s 52ms/step - loss: 1.0533e-04\n",
      "Epoch 61/100\n",
      "792/792 [==============================] - 42s 53ms/step - loss: 1.0301e-04\n",
      "Epoch 62/100\n",
      "792/792 [==============================] - 43s 55ms/step - loss: 1.0390e-04\n",
      "Epoch 63/100\n",
      "792/792 [==============================] - 40s 51ms/step - loss: 9.6703e-05\n",
      "Epoch 64/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 9.9873e-05\n",
      "Epoch 65/100\n",
      "792/792 [==============================] - 44s 56ms/step - loss: 1.0599e-04\n",
      "Epoch 66/100\n",
      "792/792 [==============================] - 39s 49ms/step - loss: 1.0351e-04\n",
      "Epoch 67/100\n",
      "792/792 [==============================] - 44s 56ms/step - loss: 1.0293e-04\n",
      "Epoch 68/100\n",
      "792/792 [==============================] - 39s 49ms/step - loss: 1.0591e-04\n",
      "Epoch 69/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 9.6549e-05\n",
      "Epoch 70/100\n",
      "792/792 [==============================] - 45s 57ms/step - loss: 9.8206e-05\n",
      "Epoch 71/100\n",
      "792/792 [==============================] - 39s 50ms/step - loss: 1.0130e-04\n",
      "Epoch 72/100\n",
      "792/792 [==============================] - 43s 55ms/step - loss: 9.6255e-05\n",
      "Epoch 73/100\n",
      "792/792 [==============================] - 41s 52ms/step - loss: 9.9141e-05\n",
      "Epoch 74/100\n",
      "792/792 [==============================] - 39s 49ms/step - loss: 9.8809e-05\n",
      "Epoch 75/100\n",
      "792/792 [==============================] - 44s 55ms/step - loss: 9.8419e-05\n",
      "Epoch 76/100\n",
      "792/792 [==============================] - 42s 52ms/step - loss: 9.5250e-05\n",
      "Epoch 77/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 1.0293e-04\n",
      "Epoch 78/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 9.9081e-05\n",
      "Epoch 79/100\n",
      "792/792 [==============================] - 39s 49ms/step - loss: 9.8503e-05\n",
      "Epoch 80/100\n",
      "792/792 [==============================] - 43s 54ms/step - loss: 9.9380e-05\n",
      "Epoch 81/100\n",
      "792/792 [==============================] - 44s 55ms/step - loss: 9.4448e-05\n",
      "Epoch 82/100\n",
      "792/792 [==============================] - 66s 83ms/step - loss: 9.8786e-05\n",
      "Epoch 83/100\n",
      "792/792 [==============================] - 53s 67ms/step - loss: 1.0006e-04\n",
      "Epoch 84/100\n",
      "792/792 [==============================] - 58s 74ms/step - loss: 9.2893e-05\n",
      "Epoch 85/100\n",
      "792/792 [==============================] - 59s 74ms/step - loss: 9.8135e-05\n",
      "Epoch 86/100\n",
      "792/792 [==============================] - 66s 83ms/step - loss: 9.8000e-05\n",
      "Epoch 87/100\n",
      "792/792 [==============================] - 67s 85ms/step - loss: 1.0150e-04\n",
      "Epoch 88/100\n",
      "792/792 [==============================] - 67s 85ms/step - loss: 9.3469e-05\n",
      "Epoch 89/100\n",
      "792/792 [==============================] - 65s 81ms/step - loss: 9.9712e-05\n",
      "Epoch 90/100\n",
      "792/792 [==============================] - 60s 75ms/step - loss: 9.8752e-05\n",
      "Epoch 91/100\n",
      "792/792 [==============================] - 56s 70ms/step - loss: 9.5697e-05\n",
      "Epoch 92/100\n",
      "792/792 [==============================] - 51s 65ms/step - loss: 9.9678e-05\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792/792 [==============================] - 59s 75ms/step - loss: 9.7758e-05\n",
      "Epoch 94/100\n",
      "792/792 [==============================] - 56s 71ms/step - loss: 9.4869e-05\n",
      "Epoch 95/100\n",
      "792/792 [==============================] - 62s 78ms/step - loss: 9.2544e-05\n",
      "Epoch 96/100\n",
      "792/792 [==============================] - 63s 79ms/step - loss: 9.8119e-05\n",
      "Epoch 97/100\n",
      "792/792 [==============================] - 64s 81ms/step - loss: 9.6480e-05\n",
      "Epoch 98/100\n",
      "792/792 [==============================] - 65s 82ms/step - loss: 9.3335e-05\n",
      "Epoch 99/100\n",
      "792/792 [==============================] - 62s 78ms/step - loss: 9.5421e-05\n",
      "Epoch 100/100\n",
      "792/792 [==============================] - 60s 76ms/step - loss: 9.4609e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217d829c9a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from numpy import array\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu', input_shape= (x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu' ))\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu' ))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17711886296243937"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = scaled_data[training_data_len - 60: , :]\n",
    "# Create the data sets x_test and y_test\n",
    "x_test = []\n",
    "y_test = dataset[training_data_len:, :]\n",
    "for i in range(60, len(test_data)):\n",
    "    x_test.append(test_data[i-60:i, 0])\n",
    "    \n",
    "# Convert the data to a numpy array\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# Reshape the data\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))\n",
    "\n",
    "# Get the models predicted price values \n",
    "predictions3 = model.predict(x_test)\n",
    "predictions3 = scaler.inverse_transform(predictions3)\n",
    "\n",
    "# Get the root mean squared error (RMSE)\n",
    "rmse = np.sqrt(np.mean(((predictions3 - y_test) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-cda6690b5d4b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_3['Predictions3'] = predictions3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07266340329740323"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100\n",
    "\n",
    "train = data[:training_data_len]\n",
    "valid_3 = data[training_data_len:]\n",
    "valid_3['Predictions3'] = predictions3\n",
    "\n",
    "mape(valid_3['Close'], valid_3['Predictions3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12732    171.438507\n",
       "12733    171.443665\n",
       "12734    171.412842\n",
       "12735    171.315643\n",
       "12736    171.317062\n",
       "            ...    \n",
       "13397    167.275223\n",
       "13398    167.396729\n",
       "13399    167.386429\n",
       "13400    167.147232\n",
       "13401    167.104126\n",
       "Name: Predictions3, Length: 670, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3['Predictions3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_data = df['Close'].values\n",
    "close_data = close_data.reshape((-1,1))\n",
    "\n",
    "split_percent = 0.95\n",
    "split = int(split_percent*len(close_data))\n",
    "\n",
    "close_train = close_data[:split]\n",
    "close_test = close_data[split:]\n",
    "\n",
    "date_train = df['Datetime'][:split]\n",
    "date_test = df['Datetime'][split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close_data = close_data.reshape((-1))\n",
    "close_data = y_train\n",
    "look_back = 60\n",
    "\n",
    "def predict(num_prediction, model):\n",
    "    prediction_list = close_data[-look_back:]\n",
    "    \n",
    "    for _ in range(num_prediction):\n",
    "        x = prediction_list[-look_back:]\n",
    "        x = x.reshape((1, look_back, 1))\n",
    "        out = model.predict(x)[0][0]\n",
    "        prediction_list = np.append(prediction_list, out)\n",
    "    prediction_list = prediction_list[look_back-1:]\n",
    "        \n",
    "    return prediction_list\n",
    "    \n",
    "def predict_dates(num_prediction):\n",
    "    #last_date = df['Datetime'].values[-1]\n",
    "    last_date = date_train.values[-1]\n",
    "    prediction_dates = pd.date_range(last_date, freq=\"min\", periods=num_prediction+1).tolist()\n",
    "    return prediction_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[171.4450073 ],\n",
       "       [171.43850795],\n",
       "       [171.443668  ],\n",
       "       [171.46894842],\n",
       "       [171.44905781],\n",
       "       [171.48512957]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_prediction = 5\n",
    "#forecast = predict(num_prediction, model)\n",
    "forecast_dates = predict_dates(num_prediction)\n",
    "\n",
    "\n",
    "forecast = predict(num_prediction, model)\n",
    "reshape_forecast = np.reshape(forecast,(forecast.shape[0],1))\n",
    "\n",
    "result = scaler.inverse_transform(reshape_forecast)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12672\n"
     ]
    }
   ],
   "source": [
    "print(len(close_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values=[171.4450073, 171.3699951,171.2998962,171.3000031, 171.2799988, 171.1900024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[171.4450073, 171.3699951, 171.2998962, 171.3000031, 171.2799988, 171.1900024]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08252329440588357"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(actual_values,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16226719336545278"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean(((result - actual_values) ** 2)))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_forecast = pd.DataFrame(result)\n",
    "\n",
    "actual_df = pd.DataFrame(actual_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
